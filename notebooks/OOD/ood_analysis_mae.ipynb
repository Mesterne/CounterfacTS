{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becd4163-1b5c-493b-be1a-f2537c6987ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f79f78a-72f9-4ff6-b6bc-86bab5b3474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/whatif/lib/python3.8/site-packages/gluonts/json.py:45: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bokeh.io.export import export_svg\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import log_cmap, linear_cmap\n",
    "from bokeh.util.hex import hexbin, cartesian_to_axial\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.loader import ValidationDataLoader\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.time_feature import (\n",
    "    HourOfDay,\n",
    "    DayOfWeek,\n",
    "    DayOfMonth,\n",
    "    DayOfYear,\n",
    "    MonthOfYear\n",
    ")\n",
    "from gluonts.torch.batchify import batchify\n",
    "from gluonts.transform import (\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    Chain,\n",
    "    InstanceSplitter,\n",
    "    ValidationSplitSampler\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.utils import get_model\n",
    "from src.utils.data_loading import load_features, load_score, load_test_data\n",
    "from src.utils.evaluation import score_batch\n",
    "from src.utils.features import decomps_and_features\n",
    "from src.utils.transformations import manipulate_trend_component, manipulate_seasonal_determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869f4000-c344-4000-b82c-fca9f05147d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generated_data(prefix, generated_test_datadir, len_test_data):\n",
    "    data = [0 for _ in range(len_test_data)]\n",
    "    for f in os.listdir(generated_test_datadir):\n",
    "        if f.startswith(prefix):\n",
    "            file_name = f.split(\".\")[0]  # slice off .npy from file name\n",
    "            ts_idx = int(file_name[len(prefix):])  # the remaining charachters after prefix is always the time series id\n",
    "            data[ts_idx] = np.load(os.path.join(generated_test_datadir, f))\n",
    "\n",
    "    data = np.array(data)  # [len(original_test), num_manipulations, 4]\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index, original_config, generated_datadir, len_test_data):\n",
    "    f_suffix = get_file_suffix(suffix, suffix_prefix_to_fname)\n",
    "    data_prefix = f\"ts_{f_suffix}\"\n",
    "    feature_prefix = f\"feat_{f_suffix}\"\n",
    "    gen_ts = load_generated_data(data_prefix, generated_datadir, len_test_data)\n",
    "    gen_features = load_generated_data(feature_prefix, generated_datadir, len_test_data)\n",
    "\n",
    "    idx = suffix_suffix_to_index[suffix[-3:]]\n",
    "    gen_ts = gen_ts[:, idx, :].reshape([-1, original_config[\"context_length\"] + original_config[\"prediction_length\"]])\n",
    "    gen_features = gen_features[:, idx, :].reshape([-1, 4])  # flatten the two first dimensions\n",
    "    return gen_ts, gen_features\n",
    "\n",
    "\n",
    "def create_gen_dataloader(generated_data, dataset, context_length, prediction_length, batch_size):\n",
    "    original_dataset = get_dataset(dataset)\n",
    "    \n",
    "    # nbeats doesn't do any covariates so we don't care that the starting points of forecasts are wrong here\n",
    "    list_data = [{\"start\": original[\"start\"], \"target\": generated, \"feat_static_cat\": original[\"feat_static_cat\"], \"item_id\": original[\"item_id\"]}\n",
    "                 for original, generated in zip(itertools.cycle(original_dataset.test), generated_data)]\n",
    "    generated_dataset = ListDataset(list_data, freq=original_dataset.metadata.freq)\n",
    "    \n",
    "    transformation = Chain([\n",
    "        AddObservedValuesIndicator(\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.OBSERVED_VALUES,\n",
    "        ),\n",
    "        AddTimeFeatures(\n",
    "            start_field=FieldName.START,\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.FEAT_TIME,\n",
    "            pred_length=prediction_length,\n",
    "            time_features=[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear(), MonthOfYear()]\n",
    "        ),\n",
    "        InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=ValidationSplitSampler(min_future=prediction_length),\n",
    "            past_length=context_length,\n",
    "            future_length=prediction_length,\n",
    "            time_series_fields=[FieldName.FEAT_TIME, FieldName.OBSERVED_VALUES]\n",
    "        )\n",
    "    ])\n",
    "    dataloader = ValidationDataLoader(\n",
    "        generated_dataset,\n",
    "        batch_size=batch_size,\n",
    "        stack_fn=batchify,\n",
    "        transform=transformation,\n",
    "        num_workers=1\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def organize_scores(all_scores, metric):\n",
    "    mape = []\n",
    "    smape = []\n",
    "    mase = []\n",
    "    seasonal_mase = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    for score in all_scores:\n",
    "        mape.append(score[0])\n",
    "        smape.append(score[1])\n",
    "        mase.append(score[2])\n",
    "        seasonal_mase.append(score[3])\n",
    "        mse.append(score[4])\n",
    "        mae.append(score[5])\n",
    "\n",
    "\n",
    "    mape = np.vstack(mape)\n",
    "    smape = np.vstack(smape)\n",
    "    mase = np.vstack(mase)\n",
    "    seasonal_mase = np.vstack(seasonal_mase)\n",
    "    mse = np.vstack(mse)\n",
    "    mae = np.vstack(mae)\n",
    "    \n",
    "    return {\"mape\": mape, \"smape\": smape, \"mase\": mase, \"seasonal_mase\": seasonal_mase, \"mse\": mse, \"mae\": mae}[metric]\n",
    "\n",
    "\n",
    "def get_scores(original_model, new_model, original_config, new_config, gen_ts, dataset, metric):\n",
    "\n",
    "    gen_dataloader = create_gen_dataloader(gen_ts, dataset, original_config[\"trainer_args\"][\"context_length\"],\n",
    "                                           original_config[\"trainer_args\"][\"prediction_length\"], original_config[\"trainer_args\"][\"batch_size\"])\n",
    "\n",
    "    original_gen_scores = []\n",
    "    new_gen_scores = []\n",
    "    original_model.eval()\n",
    "    new_model.eval()\n",
    "    for batch in tqdm(gen_dataloader):\n",
    "        original_preds = original_model.predict(batch)[:, :, 0]\n",
    "        new_preds = new_model.predict(batch)[:, :, 0]\n",
    "\n",
    "        context = batch[\"past_target\"].unsqueeze(dim=-1).numpy()\n",
    "        target = batch[\"future_target\"].numpy()\n",
    "\n",
    "        original_gen_scores.append(score_batch(target, original_preds, context, original_config[\"sp\"]))\n",
    "        new_gen_scores.append(score_batch(target, new_preds, context, new_config[\"sp\"]))\n",
    "\n",
    "    original_gen_scores = organize_scores(original_gen_scores, metric)\n",
    "    new_gen_scores = organize_scores(new_gen_scores, metric)\n",
    "    \n",
    "    return original_gen_scores, new_gen_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e434b0d4-002c-41d9-b3d9-7099b207442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_space(datadir):\n",
    "    train_features = load_features(datadir, train=True)\n",
    "    test_features = load_features(datadir, train=False)\n",
    "    scaler = StandardScaler()\n",
    "    norm_train_features = scaler.fit_transform(train_features)\n",
    "    norm_test_features = scaler.transform(test_features)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    train_pca_data = pca.fit_transform(norm_train_features)\n",
    "    test_pca_data = pca.transform(norm_test_features)\n",
    "    return pca, scaler, test_pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faaa44be-9e40-4c9a-bea9-b8340ca23989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_arr(scores, quantiles=None):\n",
    "    if quantiles is None:\n",
    "        quantiles = np.nanquantile(scores, [0.25, 0.75])\n",
    "    \n",
    "    low = scores < quantiles[0]\n",
    "    high = scores > quantiles[1]\n",
    "    medium = np.logical_and(~low, ~high)\n",
    "    \n",
    "    colors = np.empty_like(scores)\n",
    "    colors[low] = 0\n",
    "    colors[medium] = 1\n",
    "    colors[high] = 2\n",
    "    \n",
    "    return colors\n",
    "\n",
    "\n",
    "def color_bin(bins, pca_data, colors, column_name):\n",
    "    q, r = cartesian_to_axial(pca_data[:, 0], pca_data[:, 1], 0.1, \"pointytop\")\n",
    "    df = pd.DataFrame(dict(r=r, q=q))\n",
    "    groups = df.groupby([\"q\", \"r\"])\n",
    "    \n",
    "    for (q, r), indexes in groups.groups.items():\n",
    "        color = np.nanmean(colors[indexes])\n",
    "        bins.loc[(bins[\"q\"] == q) & (bins[\"r\"] == r), column_name] = color\n",
    "    \n",
    "    return bins\n",
    "\n",
    "\n",
    "def get_fig(title, xrange, yrange):\n",
    "    p = figure(title=title, tools=\"\", match_aspect=True, x_range=xrange, y_range=yrange)\n",
    "    p.output_backend = \"svg\"\n",
    "    p.title.align = \"center\"\n",
    "    p.grid.visible = False\n",
    "    return p\n",
    "\n",
    "\n",
    "def create_and_plot_hexbin(original_scores, new_scores, pca_data, figdir, dataset, suffix, model, metric, limits):\n",
    "    # create a seperate folder for each dataset and model\n",
    "    figdir = os.path.join(figdir, dataset, model)\n",
    "    if not os.path.isdir(figdir):\n",
    "        os.makedirs(figdir, exist_ok=True)\n",
    "    \n",
    "    # create hexbins\n",
    "    bins = hexbin(pca_data[:, 0], pca_data[:, 1], 0.1)\n",
    "    bins[\"original_colors\"] = np.nan\n",
    "    bins[\"new_colors\"] = np.nan\n",
    "    \n",
    "    orig_quantiles = np.nanquantile(original_scores, [0.25, 0.75])\n",
    "    original_colors = create_color_arr(original_scores, orig_quantiles)\n",
    "    new_colors = create_color_arr(new_scores, orig_quantiles)\n",
    "\n",
    "    bins = color_bin(bins, pca_data, original_colors, \"original_colors\")\n",
    "    bins = color_bin(bins, pca_data, new_colors, \"new_colors\")\n",
    "    \n",
    "    # plot original model\n",
    "    if limits is not None:\n",
    "        xrange = limits[\"xrange\"]\n",
    "        yrange = limits[\"yrange\"]\n",
    "    else:\n",
    "        xrange = None\n",
    "        yrange = None\n",
    "    \n",
    "    p = get_fig(f\"{model} trained with original training data\", xrange, yrange)\n",
    "    p.hex_tile(q=\"q\", r=\"r\", size=0.1, line_color=None, source=bins,\n",
    "                fill_color=linear_cmap(\"original_colors\", \"Viridis256\", min(bins.original_colors), max(bins.original_colors)))\n",
    "\n",
    "    export_svg(p, filename=os.path.join(figdir, f\"{dataset}_{suffix}_{model}_orig_{metric}_hexbin.svg\"))\n",
    "    \n",
    "    # plot new model\n",
    "    p = get_fig(f\"{model} trained with augmented training data\", xrange, yrange)\n",
    "    p.hex_tile(q=\"q\", r=\"r\", size=0.1, line_color=None, source=bins,\n",
    "                fill_color=linear_cmap(\"new_colors\", \"Viridis256\", min(bins.new_colors), max(bins.new_colors)))\n",
    "\n",
    "    export_svg(p, filename=os.path.join(figdir, f\"{dataset}_{suffix}_{model}_OOD_{metric}_hexbin.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8872f8-70f2-42bd-ae96-c95c88fb17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_suffix(suffix, suffix_prefix_to_fname):\n",
    "    for prefix in suffix_prefix_to_fname.keys():\n",
    "        if suffix.startswith(prefix):\n",
    "            return suffix_prefix_to_fname[prefix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f2b74d-0be1-4e8e-adc7-9a6c11b2fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataset, config):\n",
    "    test_data = load_test_data(dataset, config[\"context_length\"] + config[\"prediction_length\"])\n",
    "    \n",
    "    trend_str_inc_ts = []\n",
    "    trend_str_dec_ts = []\n",
    "    trend_lin_inc_ts = []\n",
    "    trend_lin_dec_ts = []\n",
    "    trend_slope_inc_ts = []\n",
    "    trend_slope_dec_ts = []\n",
    "    seas_str_inc_ts = []\n",
    "    seas_str_dec_ts = []\n",
    "\n",
    "    trend_str_inc_feat = []\n",
    "    trend_str_dec_feat = []\n",
    "    trend_lin_inc_feat = []\n",
    "    trend_lin_dec_feat = []\n",
    "    trend_slope_inc_feat = []\n",
    "    trend_slope_dec_feat = []\n",
    "    seas_str_inc_feat = []\n",
    "    seas_str_dec_feat = []\n",
    "    for ts in tqdm(test_data):\n",
    "        decomp = decomps_and_features([ts], config[\"sp\"])[0][0]\n",
    "        \n",
    "        inc_str = manipulate_trend_component(decomp.trend, f=100, g=1, h=1, m=0) + decomp.seasonal + decomp.resid\n",
    "        dec_str = manipulate_trend_component(decomp.trend, f=0.01, g=1, h=1, m=0) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        inc_lin = manipulate_trend_component(decomp.trend, f=1, g=1, h=100, m=0) + decomp.seasonal + decomp.resid\n",
    "        dec_lin = manipulate_trend_component(decomp.trend, f=1, g=1, h=0.01, m=0) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        inc_slope = manipulate_trend_component(decomp.trend, f=1, g=1, h=1, m=-1) + decomp.seasonal + decomp.resid\n",
    "        dec_slope = manipulate_trend_component(decomp.trend, f=1, g=1, h=1, m=1) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        generated_ts = [inc_str, dec_str, inc_lin, dec_lin, inc_slope, dec_slope]\n",
    "        if config[\"sp\"] > 1:\n",
    "            inc_seas = manipulate_seasonal_determination(decomp.seasonal, k=100) + decomp.trend + decomp.resid\n",
    "            dec_seas = manipulate_seasonal_determination(decomp.seasonal, k=0.01) + decomp.trend + decomp.resid\n",
    "            generated_ts.extend([inc_seas, dec_seas])\n",
    "            \n",
    "        _, features = decomps_and_features(generated_ts, config[\"sp\"])\n",
    "        \n",
    "        trend_str_inc_ts.append(inc_str)\n",
    "        trend_str_dec_ts.append(dec_str)\n",
    "        trend_lin_inc_ts.append(inc_lin)\n",
    "        trend_lin_dec_ts.append(dec_lin)\n",
    "        trend_slope_inc_ts.append(inc_slope)\n",
    "        trend_slope_dec_ts.append(dec_slope)\n",
    "        \n",
    "        trend_str_inc_feat.append(features[0])\n",
    "        trend_str_dec_feat.append(features[1])\n",
    "        trend_lin_inc_feat.append(features[2])\n",
    "        trend_lin_dec_feat.append(features[3])\n",
    "        trend_slope_inc_feat.append(features[4])\n",
    "        trend_slope_dec_feat.append(features[5])\n",
    "        \n",
    "        if config[\"sp\"] > 1:\n",
    "            seas_str_inc_ts.append(inc_seas)\n",
    "            seas_str_dec_ts.append(dec_seas)\n",
    "            seas_str_inc_feat.append(features[6])\n",
    "            seas_str_dec_feat.append(features[7])\n",
    "    \n",
    "    trend_str_inc_ts = np.array(trend_str_inc_ts)\n",
    "    trend_str_dec_ts = np.array(trend_str_dec_ts)\n",
    "    trend_lin_inc_ts = np.array(trend_lin_inc_ts)\n",
    "    trend_lin_dec_ts = np.array(trend_lin_dec_ts)\n",
    "    trend_slope_inc_ts = np.array(trend_slope_inc_ts)\n",
    "    trend_slope_dec_ts = np.array(trend_slope_dec_ts)\n",
    "    seas_str_inc_ts = np.array(seas_str_inc_ts)\n",
    "    seas_str_dec_ts = np.array(seas_str_dec_ts)\n",
    "    \n",
    "    trend_str_inc_feat = np.array(trend_str_inc_feat)\n",
    "    trend_str_dec_feat = np.array(trend_str_dec_feat)\n",
    "    trend_lin_inc_feat = np.array(trend_lin_inc_feat)\n",
    "    trend_lin_dec_feat = np.array(trend_lin_dec_feat)\n",
    "    trend_slope_inc_feat = np.array(trend_slope_inc_feat)\n",
    "    trend_slope_dec_feat = np.array(trend_slope_dec_feat)\n",
    "    seas_str_inc_feat = np.array(seas_str_inc_feat)\n",
    "    seas_str_dec_feat = np.array(seas_str_dec_feat)\n",
    "    \n",
    "    ts_dict = {\"trend_str_inc\": trend_str_inc_ts, \"trend_str_dec\": trend_str_dec_ts,\n",
    "               \"lin_inc\": trend_lin_inc_ts, \"lin_dec\": trend_lin_dec_ts,\n",
    "               \"slope_inc\": trend_slope_inc_ts, \"slope_dec\": trend_slope_dec_ts,\n",
    "               \"seas_inc\": seas_str_inc_ts, \"seas_dec\": seas_str_dec_ts}\n",
    "    \n",
    "    feat_dict = {\"trend_str_inc\": trend_str_inc_feat, \"trend_str_dec\": trend_str_dec_feat,\n",
    "                \"lin_inc\": trend_lin_inc_feat, \"lin_dec\": trend_lin_dec_feat,\n",
    "                \"slope_inc\": trend_slope_inc_feat, \"slope_dec\": trend_slope_dec_feat,\n",
    "                \"seas_inc\": seas_str_inc_feat, \"seas_dec\": seas_str_dec_feat}\n",
    "    \n",
    "    return ts_dict, feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e208d084-ef9d-47f7-99ee-f34ce8fa42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mae\"\n",
    "create_plots = True\n",
    "models = [\"feedforward\", \"seq2seq\", \"nbeats_g\", \"tcn\", \"transformer\"]\n",
    "model_names = [\"Fully-connected\", \"LSTM\", \"N-BEATS\", \"TCN\", \"Transformer\"]\n",
    "\n",
    "dataset_suffixes = {\n",
    "    \"electricity_nips\": [\"seas_dec\", \"slope_dec\", \"slope_inc\"],\n",
    "    \"traffic_nips\": [\"slope_inc\", \"trend_str_dec\"],  # \"seas_dec\", \"slope_dec\", \n",
    "    \"m4_hourly\": [\"slope_dec\", \"slope_inc\"],  # \"seas_dec\"\n",
    "    \"m4_daily\": [\"seas_inc\"],\n",
    "    \"m4_weekly\": [\"trend_str_dec\"],  # \"slope_dec\", \"slope_inc\", \n",
    "    \"m4_monthly\": [\"slope_inc\", \"lin_dec\", \"trend_str_dec\"],  # \"seas_dec\", \"slope_dec\", \n",
    "    \"m4_quarterly\": [\"lin_dec\", \"slope_dec\"],  # \"seas_dec\", \"seas_inc\", \n",
    "    \"m4_yearly\": [\"lin_dec\"]  # \"slope_dec\", \"slope_inc\"\n",
    "}\n",
    "plot_limits = {\n",
    "    \"electricity_nips\": {\"slope_dec\": {\"xrange\": [-5, 6], \"yrange\": [-8, 6]}, \"slope_inc\": {\"xrange\": [-3, 8], \"yrange\": [-3, 8]}},\n",
    "    \"traffic_nips\": {\"lin_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}},\n",
    "    \"m4_hourly\": {\"slope_dec\": {\"xrange\": [-10, 5], \"yrange\": [-12, 6]}},\n",
    "    \"m4_daily\": {},\n",
    "    \"m4_weekly\": {},\n",
    "    \"m4_monthly\": {\"lin_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 5]}, \"slope_dec\": {\"xrange\": [-5, 8], \"yrange\": [-5, 8]}, \"trend_str_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 8]}},\n",
    "    \"m4_quarterly\": {\"lin_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}, \"slope_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}},\n",
    "    \"m4_yearly\": {\"slope_dec\": {\"xrange\": [-10, 10], \"yrange\": [-15, 5]}, \"slope_inc\": {\"xrange\": [-10, 10], \"yrange\": [-5, 15]}, \"lin_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 5]}},\n",
    "}\n",
    "suffix_prefix_to_fname = {\"seas\": \"seasonal_str\", \"slope\": \"trend_slope\", \"lin\": \"trend_lin\", \"trend_str\": \"trend_str\"}\n",
    "suffix_suffix_to_index = {\"inc\": 98, \"dec\": -1}\n",
    "\n",
    "figdir = \"figures/OOD\"\n",
    "if not os.path.isdir(figdir):\n",
    "    os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5c198e-4c88-4c43-82e6-babff624feea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for electricity_nips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  3.81it/s]\n",
      "6it [00:02,  2.90it/s]\n",
      "6it [00:01,  3.08it/s]\n",
      "6it [00:03,  1.59it/s]\n",
      "6it [00:02,  2.02it/s]\n",
      "6it [00:01,  4.24it/s]\n",
      "6it [00:01,  3.17it/s]\n",
      "6it [00:01,  3.18it/s]\n",
      "6it [00:03,  1.57it/s]\n",
      "6it [00:02,  2.01it/s]\n",
      "6it [00:01,  4.17it/s]\n",
      "6it [00:01,  3.14it/s]\n",
      "6it [00:01,  3.35it/s]\n",
      "6it [00:03,  1.53it/s]\n",
      "6it [00:03,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for traffic_nips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:03,  3.57it/s]\n",
      "14it [00:05,  2.60it/s]\n",
      "14it [00:05,  2.62it/s]\n",
      "14it [00:09,  1.44it/s]\n",
      "14it [00:08,  1.68it/s]\n",
      "14it [00:03,  3.57it/s]\n",
      "14it [00:05,  2.53it/s]\n",
      "14it [00:05,  2.62it/s]\n",
      "14it [00:10,  1.39it/s]\n",
      "14it [00:08,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_hourly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.55it/s]\n",
      "1it [00:00,  2.85it/s]\n",
      "1it [00:00,  3.56it/s]\n",
      "1it [00:00,  1.47it/s]\n",
      "1it [00:00,  2.79it/s]\n",
      "1it [00:00,  5.43it/s]\n",
      "1it [00:00,  3.79it/s]\n",
      "1it [00:00,  3.10it/s]\n",
      "1it [00:00,  1.78it/s]\n",
      "1it [00:00,  2.46it/s]\n",
      "  0%|          | 0/4227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_daily...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4227/4227 [00:03<00:00, 1262.33it/s]\n",
      "100%|██████████| 4227/4227 [03:42<00:00, 18.96it/s]\n",
      "9it [00:01,  8.41it/s]\n",
      "9it [00:01,  6.66it/s]\n",
      "9it [00:01,  4.96it/s]\n",
      "9it [00:01,  5.06it/s]\n",
      "9it [00:01,  4.67it/s]\n",
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_weekly...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:00<00:00, 804.63it/s]\n",
      "100%|██████████| 359/359 [00:12<00:00, 27.83it/s]\n",
      "1it [00:00,  6.56it/s]\n",
      "1it [00:00,  3.79it/s]\n",
      "1it [00:00,  5.80it/s]\n",
      "1it [00:00,  5.96it/s]\n",
      "1it [00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_monthly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:13,  7.02it/s]\n",
      "94it [00:17,  5.32it/s]\n",
      "94it [00:22,  4.24it/s]\n",
      "94it [00:23,  3.96it/s]\n",
      "94it [00:23,  3.95it/s]\n",
      "94it [00:13,  7.07it/s]\n",
      "94it [00:18,  5.15it/s]\n",
      "94it [00:21,  4.28it/s]\n",
      "94it [00:23,  3.98it/s]\n",
      "94it [00:23,  4.05it/s]\n",
      "94it [00:14,  6.71it/s]\n",
      "94it [00:17,  5.30it/s]\n",
      "94it [00:22,  4.25it/s]\n",
      "94it [00:23,  4.04it/s]\n",
      "94it [00:23,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_quarterly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:05,  9.01it/s]\n",
      "47it [00:05,  7.94it/s]\n",
      "47it [00:09,  5.12it/s]\n",
      "47it [00:07,  6.68it/s]\n",
      "47it [00:07,  6.32it/s]\n",
      "47it [00:04,  9.61it/s]\n",
      "47it [00:06,  7.67it/s]\n",
      "47it [00:09,  4.90it/s]\n",
      "47it [00:07,  6.67it/s]\n",
      "47it [00:07,  6.01it/s]\n",
      "  0%|          | 0/23000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_yearly...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23000/23000 [00:10<00:00, 2170.88it/s]\n",
      "100%|██████████| 23000/23000 [12:44<00:00, 30.09it/s]\n",
      "45it [00:05,  8.48it/s]\n",
      "45it [00:06,  7.30it/s]\n",
      "45it [00:09,  4.87it/s]\n",
      "45it [00:06,  6.88it/s]\n",
      "45it [00:07,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {key: {} for key in dataset_suffixes.keys()}\n",
    "\n",
    "for dataset in dataset_suffixes.keys():\n",
    "    print(f\"Calculating scores and creating plots for {dataset}...\")\n",
    "    datadir = f\"data/{dataset}\"\n",
    "    generated_datadir = os.path.join(f\"/datadrive2/whatif/{dataset}\", \"generated\", \"test\")\n",
    "    \n",
    "    #create instance space\n",
    "    pca, scaler, test_pca_data = create_instance_space(datadir)\n",
    "    \n",
    "    # load the config and score of some random model to get metadata\n",
    "    original_experiment_dir = f\"experiments/{dataset}/nbeats_g\"\n",
    "    with open(os.path.join(original_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "        original_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    original_scores = load_score(original_experiment_dir, metric)\n",
    "    \n",
    "    if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "        generated_data, generated_features = generate_data(dataset, original_config)\n",
    "    \n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        # load data and features\n",
    "        if suffix == \"all\":\n",
    "            gen_ts = []\n",
    "            gen_features = []\n",
    "            for suffix in dataset_suffixes[dataset]:\n",
    "                if suffix == \"all\":\n",
    "                    continue\n",
    "                \n",
    "                if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "                    gen_ts_suffix = generated_data[suffix]\n",
    "                    gen_features_suffix = generated_features[suffix]\n",
    "                else:\n",
    "                    gen_ts_suffix, gen_features_suffix = load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index,\n",
    "                                                                                          original_config, generated_datadir, original_scores.shape[0])\n",
    "                gen_ts.append(gen_ts_suffix)\n",
    "                gen_features.append(gen_features_suffix)\n",
    "\n",
    "            gen_ts = np.vstack(gen_ts)\n",
    "            gen_features = np.vstack(gen_features)\n",
    "        else:\n",
    "            if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "                gen_ts = generated_data[suffix]\n",
    "                gen_features = generated_features[suffix]\n",
    "            else:\n",
    "                gen_ts, gen_features = load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index,\n",
    "                                                                        original_config, generated_datadir, original_scores.shape[0])\n",
    "\n",
    "        for model, name in zip(models, model_names):\n",
    "            # load original model\n",
    "            original_experiment_dir = f\"experiments/{dataset}/{model}\"\n",
    "            with open(os.path.join(original_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "                original_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "            original_model = get_model(original_config[\"model_name\"])(**original_config[\"model_args\"], device=device, path=original_config[\"path\"]).to(device)\n",
    "            original_model.load_state_dict(torch.load(os.path.join(original_config[\"path\"], \"model.pth\")))\n",
    "            original_scores = load_score(original_experiment_dir, metric)\n",
    "        \n",
    "            # load new model\n",
    "            new_experiment_dir = f\"experiments/{dataset}/{model}_gen_{suffix}\"\n",
    "            with open(os.path.join(new_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "                new_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "                \n",
    "            new_model = get_model(new_config[\"model_name\"])(**new_config[\"model_args\"], device=device, path=new_config[\"path\"]).to(device)\n",
    "            new_model.load_state_dict(torch.load(os.path.join(new_config[\"path\"], \"model.pth\")))\n",
    "            new_scores = load_score(new_experiment_dir, metric)\n",
    "            \n",
    "            # evaluate models on OOD test data\n",
    "            original_gen_scores, new_gen_scores = get_scores(original_model, new_model, original_config, new_config, gen_ts, dataset, metric)\n",
    "            \n",
    "            if name not in scores_dict[dataset].keys():\n",
    "                scores_dict[dataset][name] = {suffix: {\"original model\": {\"orig\": np.nanmean(original_scores), \"ood\": np.nanmean(original_gen_scores)},\n",
    "                                                       \"new model\": {\"orig\": np.nanmean(new_scores), \"ood\": np.nanmean(new_gen_scores)}}}\n",
    "            else:\n",
    "                scores_dict[dataset][name][suffix] = {\"original model\": {\"orig\": np.nanmean(original_scores), \"ood\": np.nanmean(original_gen_scores)},\n",
    "                                                      \"new model\": {\"orig\": np.nanmean(new_scores), \"ood\": np.nanmean(new_gen_scores)}}\n",
    "            \n",
    "            # concatenate scores on original test data and ood test, and calculate mean per time series\n",
    "            original_scores_concat = np.concatenate([original_scores, original_gen_scores], axis=0)\n",
    "            new_scores_concat = np.concatenate([new_scores, new_gen_scores], axis=0)\n",
    "            original_ts_scores = np.nanmean(original_scores_concat, axis=-1)\n",
    "            new_ts_scores = np.nanmean(new_scores_concat, axis=-1)\n",
    "            \n",
    "            # transform generated features to instance space and concatenate with original test data\n",
    "            norm_gen_features = scaler.transform(gen_features)\n",
    "            gen_pca_data = pca.transform(norm_gen_features)\n",
    "            concatenated_pca_data = np.concatenate([test_pca_data, gen_pca_data], axis=0)\n",
    "            \n",
    "            if create_plots:\n",
    "                limits = plot_limits[dataset].get(suffix)\n",
    "                create_and_plot_hexbin(original_ts_scores, new_ts_scores, concatenated_pca_data, figdir, dataset, suffix, name, metric, limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d0ca3e-7e0a-4bb9-87d1-50742cdb6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_to_transformation = {\"trend_str_inc\": \" (f=100)\", \"trend_str_dec\": \" (f=0.01)\",\n",
    "                            \"slope_inc\": \" (m=1)\", \"slope_dec\": \" (m=-1)\",\n",
    "                            \"lin_inc\": \" (h=100)\", \"lin_dec\": \" (h=0.01)\",\n",
    "                            \"seas_inc\": \" (k=100)\", \"seas_dec\": \" (k=0.01)\"}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for dataset in scores_dict.keys():\n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        # create a multi index for each transformation in the dataset, with one row for original data and one row for generated data\n",
    "        row_name = dataset + suffix_to_transformation[suffix]\n",
    "        tuples = [(row_name, \"original test set\"), (row_name, (\"generated test set\"))]\n",
    "        index = pd.MultiIndex.from_tuples(tuples)\n",
    "        \n",
    "        columns = []\n",
    "        old_original_scores = []\n",
    "        new_original_scores = []\n",
    "        old_generated_scores = []\n",
    "        new_generated_scores = []\n",
    "        for model in scores_dict[dataset]:\n",
    "            old_model_col = (model, \"old\")\n",
    "            new_model_col =  (model, \"augmented\")\n",
    "            columns.append(old_model_col)\n",
    "            columns.append(new_model_col)\n",
    "            \n",
    "            old_original_scores.append(scores_dict[dataset][model][suffix][\"original model\"][\"orig\"])\n",
    "            old_generated_scores.append(scores_dict[dataset][model][suffix][\"original model\"][\"ood\"])\n",
    "            new_original_scores.append(scores_dict[dataset][model][suffix][\"new model\"][\"orig\"])\n",
    "            new_generated_scores.append(scores_dict[dataset][model][suffix][\"new model\"][\"ood\"])\n",
    "        \n",
    "        \n",
    "        zipped_original = []\n",
    "        for old, new in zip(old_original_scores, new_original_scores):\n",
    "            zipped_original.append(np.round(old, 3))\n",
    "            \n",
    "            percentage = np.round((np.abs(old - new) / old) * 100, 3)\n",
    "            percentage_str = \"+\" + str(percentage) if new >= old else \"-\" + str(percentage)\n",
    "            new = f\"{np.round(new, 3)} ({percentage_str}%)\"\n",
    "            zipped_original.append(new)\n",
    "            \n",
    "            \n",
    "        zipped_generated = []\n",
    "        for old, new in zip(old_generated_scores, new_generated_scores):\n",
    "            zipped_generated.append(np.round(old, 3))\n",
    "            \n",
    "            percentage = np.round((np.abs(old - new) / old) * 100, 3)\n",
    "            percentage_str = \"+\" + str(percentage) if new >= old else \"-\" + str(percentage)\n",
    "            new = f\"{np.round(new, 3)} ({percentage_str}%)\"\n",
    "            zipped_generated.append(new)\n",
    "        \n",
    "        suffix_df = pd.DataFrame(np.vstack([zipped_original, zipped_generated]), columns=columns)\n",
    "        suffix_df.index = index\n",
    "        suffix_df.columns = pd.MultiIndex.from_tuples(suffix_df.columns)\n",
    "        df = pd.concat([df, suffix_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dfc06b-ddc8-4dbe-b937-30e8fd1e9378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fully-connected</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSTM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">N-BEATS</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TCN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Transformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (k=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>58.41</td>\n",
       "      <td>63.663 (+8.994%)</td>\n",
       "      <td>53.361</td>\n",
       "      <td>59.56 (+11.618%)</td>\n",
       "      <td>44.002</td>\n",
       "      <td>44.284 (+0.642%)</td>\n",
       "      <td>53.067</td>\n",
       "      <td>74.053 (+39.547%)</td>\n",
       "      <td>51.421</td>\n",
       "      <td>53.983 (+4.982%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>39.696</td>\n",
       "      <td>30.907 (-22.141%)</td>\n",
       "      <td>43.864</td>\n",
       "      <td>42.126 (-3.962%)</td>\n",
       "      <td>38.066</td>\n",
       "      <td>25.911 (-31.933%)</td>\n",
       "      <td>39.43</td>\n",
       "      <td>35.993 (-8.715%)</td>\n",
       "      <td>40.159</td>\n",
       "      <td>32.635 (-18.736%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>58.41</td>\n",
       "      <td>48.889 (-16.299%)</td>\n",
       "      <td>53.361</td>\n",
       "      <td>56.733 (+6.32%)</td>\n",
       "      <td>44.002</td>\n",
       "      <td>44.581 (+1.316%)</td>\n",
       "      <td>53.067</td>\n",
       "      <td>52.674 (-0.74%)</td>\n",
       "      <td>51.421</td>\n",
       "      <td>50.602 (-1.593%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>315.842</td>\n",
       "      <td>52.343 (-83.427%)</td>\n",
       "      <td>309.964</td>\n",
       "      <td>174.621 (-43.664%)</td>\n",
       "      <td>111.604</td>\n",
       "      <td>55.5 (-50.27%)</td>\n",
       "      <td>244.093</td>\n",
       "      <td>72.32 (-70.372%)</td>\n",
       "      <td>244.993</td>\n",
       "      <td>62.651 (-74.428%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>58.41</td>\n",
       "      <td>49.359 (-15.495%)</td>\n",
       "      <td>53.361</td>\n",
       "      <td>61.706 (+15.64%)</td>\n",
       "      <td>44.002</td>\n",
       "      <td>44.079 (+0.176%)</td>\n",
       "      <td>53.067</td>\n",
       "      <td>55.908 (+5.354%)</td>\n",
       "      <td>51.421</td>\n",
       "      <td>54.598 (+6.178%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>246.497</td>\n",
       "      <td>53.815 (-78.168%)</td>\n",
       "      <td>335.354</td>\n",
       "      <td>147.311 (-56.073%)</td>\n",
       "      <td>162.909</td>\n",
       "      <td>60.974 (-62.572%)</td>\n",
       "      <td>203.868</td>\n",
       "      <td>75.164 (-63.131%)</td>\n",
       "      <td>201.305</td>\n",
       "      <td>82.859 (-58.839%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">traffic_nips (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008 (+5.663%)</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009 (+7.231%)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005 (+2.507%)</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.01 (+35.766%)</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.028 (+205.099%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008 (-46.047%)</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023 (-16.634%)</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.007 (-48.256%)</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.017 (-47.355%)</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.031 (-23.248%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">traffic_nips (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008 (+0.394%)</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008 (-4.143%)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006 (+3.841%)</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012 (+61.554%)</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.026 (+191.278%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009 (-0.429%)</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019 (-22.352%)</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008 (-0.766%)</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013 (-2.98%)</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.026 (-16.51%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_hourly (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>285.752</td>\n",
       "      <td>332.324 (+16.298%)</td>\n",
       "      <td>530.073</td>\n",
       "      <td>359.344 (-32.209%)</td>\n",
       "      <td>387.313</td>\n",
       "      <td>300.203 (-22.491%)</td>\n",
       "      <td>310.46</td>\n",
       "      <td>577.916 (+86.148%)</td>\n",
       "      <td>363.743</td>\n",
       "      <td>438.258 (+20.485%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>4044.765</td>\n",
       "      <td>629.797 (-84.429%)</td>\n",
       "      <td>4095.786</td>\n",
       "      <td>718.622 (-82.455%)</td>\n",
       "      <td>4977.778</td>\n",
       "      <td>657.757 (-86.786%)</td>\n",
       "      <td>4442.087</td>\n",
       "      <td>840.151 (-81.087%)</td>\n",
       "      <td>4435.814</td>\n",
       "      <td>693.564 (-84.364%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_hourly (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>285.752</td>\n",
       "      <td>504.937 (+76.705%)</td>\n",
       "      <td>530.073</td>\n",
       "      <td>316.841 (-40.227%)</td>\n",
       "      <td>387.313</td>\n",
       "      <td>373.598 (-3.541%)</td>\n",
       "      <td>310.46</td>\n",
       "      <td>396.511 (+27.717%)</td>\n",
       "      <td>363.743</td>\n",
       "      <td>352.61 (-3.061%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>3156.815</td>\n",
       "      <td>686.334 (-78.259%)</td>\n",
       "      <td>3579.044</td>\n",
       "      <td>585.751 (-83.634%)</td>\n",
       "      <td>3587.283</td>\n",
       "      <td>439.313 (-87.754%)</td>\n",
       "      <td>4792.464</td>\n",
       "      <td>2306.926 (-51.863%)</td>\n",
       "      <td>3939.253</td>\n",
       "      <td>988.161 (-74.915%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_daily (k=100)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>180.823</td>\n",
       "      <td>184.145 (+1.837%)</td>\n",
       "      <td>180.538</td>\n",
       "      <td>179.869 (-0.371%)</td>\n",
       "      <td>176.184</td>\n",
       "      <td>176.107 (-0.044%)</td>\n",
       "      <td>186.772</td>\n",
       "      <td>179.482 (-3.903%)</td>\n",
       "      <td>180.101</td>\n",
       "      <td>178.252 (-1.027%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>5097.152</td>\n",
       "      <td>2459.157 (-51.754%)</td>\n",
       "      <td>4832.058</td>\n",
       "      <td>2282.26 (-52.768%)</td>\n",
       "      <td>4838.892</td>\n",
       "      <td>2314.794 (-52.163%)</td>\n",
       "      <td>4878.213</td>\n",
       "      <td>2466.513 (-49.438%)</td>\n",
       "      <td>4787.081</td>\n",
       "      <td>2723.599 (-43.105%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_weekly (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>305.795</td>\n",
       "      <td>317.963 (+3.979%)</td>\n",
       "      <td>330.376</td>\n",
       "      <td>342.834 (+3.771%)</td>\n",
       "      <td>342.279</td>\n",
       "      <td>356.011 (+4.012%)</td>\n",
       "      <td>343.894</td>\n",
       "      <td>371.897 (+8.143%)</td>\n",
       "      <td>330.943</td>\n",
       "      <td>349.955 (+5.745%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1370.924</td>\n",
       "      <td>545.287 (-60.225%)</td>\n",
       "      <td>1072.014</td>\n",
       "      <td>521.377 (-51.365%)</td>\n",
       "      <td>236.57</td>\n",
       "      <td>162.882 (-31.149%)</td>\n",
       "      <td>992.923</td>\n",
       "      <td>712.984 (-28.193%)</td>\n",
       "      <td>214.704</td>\n",
       "      <td>181.355 (-15.532%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>599.508</td>\n",
       "      <td>614.42 (+2.487%)</td>\n",
       "      <td>578.395</td>\n",
       "      <td>598.135 (+3.413%)</td>\n",
       "      <td>543.125</td>\n",
       "      <td>557.961 (+2.731%)</td>\n",
       "      <td>607.586</td>\n",
       "      <td>681.44 (+12.155%)</td>\n",
       "      <td>593.16</td>\n",
       "      <td>630.708 (+6.33%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>730.01</td>\n",
       "      <td>614.547 (-15.817%)</td>\n",
       "      <td>686.014</td>\n",
       "      <td>600.295 (-12.495%)</td>\n",
       "      <td>856.948</td>\n",
       "      <td>580.417 (-32.269%)</td>\n",
       "      <td>773.443</td>\n",
       "      <td>659.565 (-14.724%)</td>\n",
       "      <td>802.441</td>\n",
       "      <td>630.376 (-21.443%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>599.508</td>\n",
       "      <td>675.136 (+12.615%)</td>\n",
       "      <td>578.395</td>\n",
       "      <td>610.934 (+5.626%)</td>\n",
       "      <td>543.125</td>\n",
       "      <td>553.251 (+1.864%)</td>\n",
       "      <td>607.586</td>\n",
       "      <td>980.701 (+61.409%)</td>\n",
       "      <td>593.16</td>\n",
       "      <td>662.76 (+11.734%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>28597.189</td>\n",
       "      <td>17923.248 (-37.325%)</td>\n",
       "      <td>25665.182</td>\n",
       "      <td>14539.581 (-43.349%)</td>\n",
       "      <td>24330.667</td>\n",
       "      <td>15835.171 (-34.917%)</td>\n",
       "      <td>29048.515</td>\n",
       "      <td>17295.919 (-40.459%)</td>\n",
       "      <td>28854.079</td>\n",
       "      <td>22039.445 (-23.618%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>599.508</td>\n",
       "      <td>583.48 (-2.673%)</td>\n",
       "      <td>578.395</td>\n",
       "      <td>577.47 (-0.16%)</td>\n",
       "      <td>543.125</td>\n",
       "      <td>543.73 (+0.111%)</td>\n",
       "      <td>607.586</td>\n",
       "      <td>612.072 (+0.738%)</td>\n",
       "      <td>593.16</td>\n",
       "      <td>583.062 (-1.702%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>379.357</td>\n",
       "      <td>304.517 (-19.728%)</td>\n",
       "      <td>369.606</td>\n",
       "      <td>300.902 (-18.589%)</td>\n",
       "      <td>332.974</td>\n",
       "      <td>293.062 (-11.987%)</td>\n",
       "      <td>395.106</td>\n",
       "      <td>321.762 (-18.563%)</td>\n",
       "      <td>390.73</td>\n",
       "      <td>315.97 (-19.133%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_quarterly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>601.418</td>\n",
       "      <td>662.194 (+10.106%)</td>\n",
       "      <td>593.796</td>\n",
       "      <td>645.512 (+8.709%)</td>\n",
       "      <td>549.069</td>\n",
       "      <td>562.453 (+2.438%)</td>\n",
       "      <td>586.797</td>\n",
       "      <td>659.522 (+12.394%)</td>\n",
       "      <td>619.836</td>\n",
       "      <td>693.36 (+11.862%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>37976.754</td>\n",
       "      <td>27645.278 (-27.205%)</td>\n",
       "      <td>33722.531</td>\n",
       "      <td>24824.17 (-26.387%)</td>\n",
       "      <td>33184.391</td>\n",
       "      <td>27129.669 (-18.246%)</td>\n",
       "      <td>34644.927</td>\n",
       "      <td>21912.904 (-36.75%)</td>\n",
       "      <td>37737.281</td>\n",
       "      <td>31564.946 (-16.356%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_quarterly (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>601.418</td>\n",
       "      <td>612.979 (+1.922%)</td>\n",
       "      <td>593.796</td>\n",
       "      <td>610.975 (+2.893%)</td>\n",
       "      <td>549.069</td>\n",
       "      <td>586.319 (+6.784%)</td>\n",
       "      <td>586.797</td>\n",
       "      <td>618.783 (+5.451%)</td>\n",
       "      <td>619.836</td>\n",
       "      <td>693.07 (+11.815%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1365.815</td>\n",
       "      <td>677.806 (-50.374%)</td>\n",
       "      <td>1296.877</td>\n",
       "      <td>656.002 (-49.417%)</td>\n",
       "      <td>1496.897</td>\n",
       "      <td>637.207 (-57.431%)</td>\n",
       "      <td>1556.312</td>\n",
       "      <td>707.03 (-54.57%)</td>\n",
       "      <td>1356.687</td>\n",
       "      <td>740.236 (-45.438%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_yearly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>856.154</td>\n",
       "      <td>941.741 (+9.997%)</td>\n",
       "      <td>909.995</td>\n",
       "      <td>1082.577 (+18.965%)</td>\n",
       "      <td>836.153</td>\n",
       "      <td>860.36 (+2.895%)</td>\n",
       "      <td>882.914</td>\n",
       "      <td>969.431 (+9.799%)</td>\n",
       "      <td>888.936</td>\n",
       "      <td>890.305 (+0.154%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>24146.394</td>\n",
       "      <td>20045.627 (-16.983%)</td>\n",
       "      <td>26061.999</td>\n",
       "      <td>26058.511 (-0.013%)</td>\n",
       "      <td>22951.076</td>\n",
       "      <td>14019.047 (-38.918%)</td>\n",
       "      <td>24956.773</td>\n",
       "      <td>22856.016 (-8.418%)</td>\n",
       "      <td>34480.49</td>\n",
       "      <td>28419.593 (-17.578%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Fully-connected  \\\n",
       "                                                         old   \n",
       "electricity_nips (k=0.01) original test set            58.41   \n",
       "                          generated test set          39.696   \n",
       "electricity_nips (m=-1)   original test set            58.41   \n",
       "                          generated test set         315.842   \n",
       "electricity_nips (m=1)    original test set            58.41   \n",
       "                          generated test set         246.497   \n",
       "traffic_nips (m=1)        original test set            0.007   \n",
       "                          generated test set           0.015   \n",
       "traffic_nips (f=0.01)     original test set            0.007   \n",
       "                          generated test set           0.009   \n",
       "m4_hourly (m=-1)          original test set          285.752   \n",
       "                          generated test set        4044.765   \n",
       "m4_hourly (m=1)           original test set          285.752   \n",
       "                          generated test set        3156.815   \n",
       "m4_daily (k=100)          original test set          180.823   \n",
       "                          generated test set        5097.152   \n",
       "m4_weekly (f=0.01)        original test set          305.795   \n",
       "                          generated test set        1370.924   \n",
       "m4_monthly (m=1)          original test set          599.508   \n",
       "                          generated test set          730.01   \n",
       "m4_monthly (h=0.01)       original test set          599.508   \n",
       "                          generated test set       28597.189   \n",
       "m4_monthly (f=0.01)       original test set          599.508   \n",
       "                          generated test set         379.357   \n",
       "m4_quarterly (h=0.01)     original test set          601.418   \n",
       "                          generated test set       37976.754   \n",
       "m4_quarterly (m=-1)       original test set          601.418   \n",
       "                          generated test set        1365.815   \n",
       "m4_yearly (h=0.01)        original test set          856.154   \n",
       "                          generated test set       24146.394   \n",
       "\n",
       "                                                                         LSTM  \\\n",
       "                                                         augmented        old   \n",
       "electricity_nips (k=0.01) original test set       63.663 (+8.994%)     53.361   \n",
       "                          generated test set     30.907 (-22.141%)     43.864   \n",
       "electricity_nips (m=-1)   original test set      48.889 (-16.299%)     53.361   \n",
       "                          generated test set     52.343 (-83.427%)    309.964   \n",
       "electricity_nips (m=1)    original test set      49.359 (-15.495%)     53.361   \n",
       "                          generated test set     53.815 (-78.168%)    335.354   \n",
       "traffic_nips (m=1)        original test set        0.008 (+5.663%)      0.009   \n",
       "                          generated test set      0.008 (-46.047%)      0.027   \n",
       "traffic_nips (f=0.01)     original test set        0.008 (+0.394%)      0.009   \n",
       "                          generated test set       0.009 (-0.429%)      0.024   \n",
       "m4_hourly (m=-1)          original test set     332.324 (+16.298%)    530.073   \n",
       "                          generated test set    629.797 (-84.429%)   4095.786   \n",
       "m4_hourly (m=1)           original test set     504.937 (+76.705%)    530.073   \n",
       "                          generated test set    686.334 (-78.259%)   3579.044   \n",
       "m4_daily (k=100)          original test set      184.145 (+1.837%)    180.538   \n",
       "                          generated test set   2459.157 (-51.754%)   4832.058   \n",
       "m4_weekly (f=0.01)        original test set      317.963 (+3.979%)    330.376   \n",
       "                          generated test set    545.287 (-60.225%)   1072.014   \n",
       "m4_monthly (m=1)          original test set       614.42 (+2.487%)    578.395   \n",
       "                          generated test set    614.547 (-15.817%)    686.014   \n",
       "m4_monthly (h=0.01)       original test set     675.136 (+12.615%)    578.395   \n",
       "                          generated test set  17923.248 (-37.325%)  25665.182   \n",
       "m4_monthly (f=0.01)       original test set       583.48 (-2.673%)    578.395   \n",
       "                          generated test set    304.517 (-19.728%)    369.606   \n",
       "m4_quarterly (h=0.01)     original test set     662.194 (+10.106%)    593.796   \n",
       "                          generated test set  27645.278 (-27.205%)  33722.531   \n",
       "m4_quarterly (m=-1)       original test set      612.979 (+1.922%)    593.796   \n",
       "                          generated test set    677.806 (-50.374%)   1296.877   \n",
       "m4_yearly (h=0.01)        original test set      941.741 (+9.997%)    909.995   \n",
       "                          generated test set  20045.627 (-16.983%)  26061.999   \n",
       "\n",
       "                                                                      N-BEATS  \\\n",
       "                                                         augmented        old   \n",
       "electricity_nips (k=0.01) original test set       59.56 (+11.618%)     44.002   \n",
       "                          generated test set      42.126 (-3.962%)     38.066   \n",
       "electricity_nips (m=-1)   original test set        56.733 (+6.32%)     44.002   \n",
       "                          generated test set    174.621 (-43.664%)    111.604   \n",
       "electricity_nips (m=1)    original test set       61.706 (+15.64%)     44.002   \n",
       "                          generated test set    147.311 (-56.073%)    162.909   \n",
       "traffic_nips (m=1)        original test set        0.009 (+7.231%)      0.005   \n",
       "                          generated test set      0.023 (-16.634%)      0.014   \n",
       "traffic_nips (f=0.01)     original test set        0.008 (-4.143%)      0.005   \n",
       "                          generated test set      0.019 (-22.352%)      0.008   \n",
       "m4_hourly (m=-1)          original test set     359.344 (-32.209%)    387.313   \n",
       "                          generated test set    718.622 (-82.455%)   4977.778   \n",
       "m4_hourly (m=1)           original test set     316.841 (-40.227%)    387.313   \n",
       "                          generated test set    585.751 (-83.634%)   3587.283   \n",
       "m4_daily (k=100)          original test set      179.869 (-0.371%)    176.184   \n",
       "                          generated test set    2282.26 (-52.768%)   4838.892   \n",
       "m4_weekly (f=0.01)        original test set      342.834 (+3.771%)    342.279   \n",
       "                          generated test set    521.377 (-51.365%)     236.57   \n",
       "m4_monthly (m=1)          original test set      598.135 (+3.413%)    543.125   \n",
       "                          generated test set    600.295 (-12.495%)    856.948   \n",
       "m4_monthly (h=0.01)       original test set      610.934 (+5.626%)    543.125   \n",
       "                          generated test set  14539.581 (-43.349%)  24330.667   \n",
       "m4_monthly (f=0.01)       original test set        577.47 (-0.16%)    543.125   \n",
       "                          generated test set    300.902 (-18.589%)    332.974   \n",
       "m4_quarterly (h=0.01)     original test set      645.512 (+8.709%)    549.069   \n",
       "                          generated test set   24824.17 (-26.387%)  33184.391   \n",
       "m4_quarterly (m=-1)       original test set      610.975 (+2.893%)    549.069   \n",
       "                          generated test set    656.002 (-49.417%)   1496.897   \n",
       "m4_yearly (h=0.01)        original test set    1082.577 (+18.965%)    836.153   \n",
       "                          generated test set   26058.511 (-0.013%)  22951.076   \n",
       "\n",
       "                                                                          TCN  \\\n",
       "                                                         augmented        old   \n",
       "electricity_nips (k=0.01) original test set       44.284 (+0.642%)     53.067   \n",
       "                          generated test set     25.911 (-31.933%)      39.43   \n",
       "electricity_nips (m=-1)   original test set       44.581 (+1.316%)     53.067   \n",
       "                          generated test set        55.5 (-50.27%)    244.093   \n",
       "electricity_nips (m=1)    original test set       44.079 (+0.176%)     53.067   \n",
       "                          generated test set     60.974 (-62.572%)    203.868   \n",
       "traffic_nips (m=1)        original test set        0.005 (+2.507%)      0.008   \n",
       "                          generated test set      0.007 (-48.256%)      0.031   \n",
       "traffic_nips (f=0.01)     original test set        0.006 (+3.841%)      0.008   \n",
       "                          generated test set       0.008 (-0.766%)      0.014   \n",
       "m4_hourly (m=-1)          original test set     300.203 (-22.491%)     310.46   \n",
       "                          generated test set    657.757 (-86.786%)   4442.087   \n",
       "m4_hourly (m=1)           original test set      373.598 (-3.541%)     310.46   \n",
       "                          generated test set    439.313 (-87.754%)   4792.464   \n",
       "m4_daily (k=100)          original test set      176.107 (-0.044%)    186.772   \n",
       "                          generated test set   2314.794 (-52.163%)   4878.213   \n",
       "m4_weekly (f=0.01)        original test set      356.011 (+4.012%)    343.894   \n",
       "                          generated test set    162.882 (-31.149%)    992.923   \n",
       "m4_monthly (m=1)          original test set      557.961 (+2.731%)    607.586   \n",
       "                          generated test set    580.417 (-32.269%)    773.443   \n",
       "m4_monthly (h=0.01)       original test set      553.251 (+1.864%)    607.586   \n",
       "                          generated test set  15835.171 (-34.917%)  29048.515   \n",
       "m4_monthly (f=0.01)       original test set       543.73 (+0.111%)    607.586   \n",
       "                          generated test set    293.062 (-11.987%)    395.106   \n",
       "m4_quarterly (h=0.01)     original test set      562.453 (+2.438%)    586.797   \n",
       "                          generated test set  27129.669 (-18.246%)  34644.927   \n",
       "m4_quarterly (m=-1)       original test set      586.319 (+6.784%)    586.797   \n",
       "                          generated test set    637.207 (-57.431%)   1556.312   \n",
       "m4_yearly (h=0.01)        original test set       860.36 (+2.895%)    882.914   \n",
       "                          generated test set  14019.047 (-38.918%)  24956.773   \n",
       "\n",
       "                                                                    \\\n",
       "                                                         augmented   \n",
       "electricity_nips (k=0.01) original test set      74.053 (+39.547%)   \n",
       "                          generated test set      35.993 (-8.715%)   \n",
       "electricity_nips (m=-1)   original test set        52.674 (-0.74%)   \n",
       "                          generated test set      72.32 (-70.372%)   \n",
       "electricity_nips (m=1)    original test set       55.908 (+5.354%)   \n",
       "                          generated test set     75.164 (-63.131%)   \n",
       "traffic_nips (m=1)        original test set        0.01 (+35.766%)   \n",
       "                          generated test set      0.017 (-47.355%)   \n",
       "traffic_nips (f=0.01)     original test set       0.012 (+61.554%)   \n",
       "                          generated test set        0.013 (-2.98%)   \n",
       "m4_hourly (m=-1)          original test set     577.916 (+86.148%)   \n",
       "                          generated test set    840.151 (-81.087%)   \n",
       "m4_hourly (m=1)           original test set     396.511 (+27.717%)   \n",
       "                          generated test set   2306.926 (-51.863%)   \n",
       "m4_daily (k=100)          original test set      179.482 (-3.903%)   \n",
       "                          generated test set   2466.513 (-49.438%)   \n",
       "m4_weekly (f=0.01)        original test set      371.897 (+8.143%)   \n",
       "                          generated test set    712.984 (-28.193%)   \n",
       "m4_monthly (m=1)          original test set      681.44 (+12.155%)   \n",
       "                          generated test set    659.565 (-14.724%)   \n",
       "m4_monthly (h=0.01)       original test set     980.701 (+61.409%)   \n",
       "                          generated test set  17295.919 (-40.459%)   \n",
       "m4_monthly (f=0.01)       original test set      612.072 (+0.738%)   \n",
       "                          generated test set    321.762 (-18.563%)   \n",
       "m4_quarterly (h=0.01)     original test set     659.522 (+12.394%)   \n",
       "                          generated test set   21912.904 (-36.75%)   \n",
       "m4_quarterly (m=-1)       original test set      618.783 (+5.451%)   \n",
       "                          generated test set      707.03 (-54.57%)   \n",
       "m4_yearly (h=0.01)        original test set      969.431 (+9.799%)   \n",
       "                          generated test set   22856.016 (-8.418%)   \n",
       "\n",
       "                                             Transformer                        \n",
       "                                                     old             augmented  \n",
       "electricity_nips (k=0.01) original test set       51.421      53.983 (+4.982%)  \n",
       "                          generated test set      40.159     32.635 (-18.736%)  \n",
       "electricity_nips (m=-1)   original test set       51.421      50.602 (-1.593%)  \n",
       "                          generated test set     244.993     62.651 (-74.428%)  \n",
       "electricity_nips (m=1)    original test set       51.421      54.598 (+6.178%)  \n",
       "                          generated test set     201.305     82.859 (-58.839%)  \n",
       "traffic_nips (m=1)        original test set        0.009     0.028 (+205.099%)  \n",
       "                          generated test set        0.04      0.031 (-23.248%)  \n",
       "traffic_nips (f=0.01)     original test set        0.009     0.026 (+191.278%)  \n",
       "                          generated test set       0.031       0.026 (-16.51%)  \n",
       "m4_hourly (m=-1)          original test set      363.743    438.258 (+20.485%)  \n",
       "                          generated test set    4435.814    693.564 (-84.364%)  \n",
       "m4_hourly (m=1)           original test set      363.743      352.61 (-3.061%)  \n",
       "                          generated test set    3939.253    988.161 (-74.915%)  \n",
       "m4_daily (k=100)          original test set      180.101     178.252 (-1.027%)  \n",
       "                          generated test set    4787.081   2723.599 (-43.105%)  \n",
       "m4_weekly (f=0.01)        original test set      330.943     349.955 (+5.745%)  \n",
       "                          generated test set     214.704    181.355 (-15.532%)  \n",
       "m4_monthly (m=1)          original test set       593.16      630.708 (+6.33%)  \n",
       "                          generated test set     802.441    630.376 (-21.443%)  \n",
       "m4_monthly (h=0.01)       original test set       593.16     662.76 (+11.734%)  \n",
       "                          generated test set   28854.079  22039.445 (-23.618%)  \n",
       "m4_monthly (f=0.01)       original test set       593.16     583.062 (-1.702%)  \n",
       "                          generated test set      390.73     315.97 (-19.133%)  \n",
       "m4_quarterly (h=0.01)     original test set      619.836     693.36 (+11.862%)  \n",
       "                          generated test set   37737.281  31564.946 (-16.356%)  \n",
       "m4_quarterly (m=-1)       original test set      619.836     693.07 (+11.815%)  \n",
       "                          generated test set    1356.687    740.236 (-45.438%)  \n",
       "m4_yearly (h=0.01)        original test set      888.936     890.305 (+0.154%)  \n",
       "                          generated test set    34480.49  28419.593 (-17.578%)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c289e4f-f3e1-4698-8c75-50bddfb43caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|ll|cc|cc|cc|cc|cc|}\n",
      "\\toprule\n",
      "                   &                    & \\multicolumn{2}{c}{Fully-connected} & \\multicolumn{2}{c}{LSTM} & \\multicolumn{2}{c}{N-BEATS} & \\multicolumn{2}{c}{TCN} & \\multicolumn{2}{c}{Transformer} \\\\\n",
      "                   &                    &             old &             augmented &        old &             augmented &        old &             augmented &        old &             augmented &         old &             augmented \\\\\n",
      "\\midrule\n",
      "\\multirow{2}{*}{electricity\\_nips (k=0.01)} & original test set &           58.41 &      63.663 (+8.994\\%) &     53.361 &      59.56 (+11.618\\%) &     44.002 &      44.284 (+0.642\\%) &     53.067 &     74.053 (+39.547\\%) &      51.421 &      53.983 (+4.982\\%) \\\\\n",
      "                   & generated test set &          39.696 &     30.907 (-22.141\\%) &     43.864 &      42.126 (-3.962\\%) &     38.066 &     25.911 (-31.933\\%) &      39.43 &      35.993 (-8.715\\%) &      40.159 &     32.635 (-18.736\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{electricity\\_nips (m=-1)} & original test set &           58.41 &     48.889 (-16.299\\%) &     53.361 &       56.733 (+6.32\\%) &     44.002 &      44.581 (+1.316\\%) &     53.067 &       52.674 (-0.74\\%) &      51.421 &      50.602 (-1.593\\%) \\\\\n",
      "                   & generated test set &         315.842 &     52.343 (-83.427\\%) &    309.964 &    174.621 (-43.664\\%) &    111.604 &        55.5 (-50.27\\%) &    244.093 &      72.32 (-70.372\\%) &     244.993 &     62.651 (-74.428\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{electricity\\_nips (m=1)} & original test set &           58.41 &     49.359 (-15.495\\%) &     53.361 &      61.706 (+15.64\\%) &     44.002 &      44.079 (+0.176\\%) &     53.067 &      55.908 (+5.354\\%) &      51.421 &      54.598 (+6.178\\%) \\\\\n",
      "                   & generated test set &         246.497 &     53.815 (-78.168\\%) &    335.354 &    147.311 (-56.073\\%) &    162.909 &     60.974 (-62.572\\%) &    203.868 &     75.164 (-63.131\\%) &     201.305 &     82.859 (-58.839\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{traffic\\_nips (m=1)} & original test set &           0.007 &       0.008 (+5.663\\%) &      0.009 &       0.009 (+7.231\\%) &      0.005 &       0.005 (+2.507\\%) &      0.008 &       0.01 (+35.766\\%) &       0.009 &     0.028 (+205.099\\%) \\\\\n",
      "                   & generated test set &           0.015 &      0.008 (-46.047\\%) &      0.027 &      0.023 (-16.634\\%) &      0.014 &      0.007 (-48.256\\%) &      0.031 &      0.017 (-47.355\\%) &        0.04 &      0.031 (-23.248\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{traffic\\_nips (f=0.01)} & original test set &           0.007 &       0.008 (+0.394\\%) &      0.009 &       0.008 (-4.143\\%) &      0.005 &       0.006 (+3.841\\%) &      0.008 &      0.012 (+61.554\\%) &       0.009 &     0.026 (+191.278\\%) \\\\\n",
      "                   & generated test set &           0.009 &       0.009 (-0.429\\%) &      0.024 &      0.019 (-22.352\\%) &      0.008 &       0.008 (-0.766\\%) &      0.014 &        0.013 (-2.98\\%) &       0.031 &       0.026 (-16.51\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_hourly (m=-1)} & original test set &         285.752 &    332.324 (+16.298\\%) &    530.073 &    359.344 (-32.209\\%) &    387.313 &    300.203 (-22.491\\%) &     310.46 &    577.916 (+86.148\\%) &     363.743 &    438.258 (+20.485\\%) \\\\\n",
      "                   & generated test set &        4044.765 &    629.797 (-84.429\\%) &   4095.786 &    718.622 (-82.455\\%) &   4977.778 &    657.757 (-86.786\\%) &   4442.087 &    840.151 (-81.087\\%) &    4435.814 &    693.564 (-84.364\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_hourly (m=1)} & original test set &         285.752 &    504.937 (+76.705\\%) &    530.073 &    316.841 (-40.227\\%) &    387.313 &     373.598 (-3.541\\%) &     310.46 &    396.511 (+27.717\\%) &     363.743 &      352.61 (-3.061\\%) \\\\\n",
      "                   & generated test set &        3156.815 &    686.334 (-78.259\\%) &   3579.044 &    585.751 (-83.634\\%) &   3587.283 &    439.313 (-87.754\\%) &   4792.464 &   2306.926 (-51.863\\%) &    3939.253 &    988.161 (-74.915\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_daily (k=100)} & original test set &         180.823 &     184.145 (+1.837\\%) &    180.538 &     179.869 (-0.371\\%) &    176.184 &     176.107 (-0.044\\%) &    186.772 &     179.482 (-3.903\\%) &     180.101 &     178.252 (-1.027\\%) \\\\\n",
      "                   & generated test set &        5097.152 &   2459.157 (-51.754\\%) &   4832.058 &    2282.26 (-52.768\\%) &   4838.892 &   2314.794 (-52.163\\%) &   4878.213 &   2466.513 (-49.438\\%) &    4787.081 &   2723.599 (-43.105\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_weekly (f=0.01)} & original test set &         305.795 &     317.963 (+3.979\\%) &    330.376 &     342.834 (+3.771\\%) &    342.279 &     356.011 (+4.012\\%) &    343.894 &     371.897 (+8.143\\%) &     330.943 &     349.955 (+5.745\\%) \\\\\n",
      "                   & generated test set &        1370.924 &    545.287 (-60.225\\%) &   1072.014 &    521.377 (-51.365\\%) &     236.57 &    162.882 (-31.149\\%) &    992.923 &    712.984 (-28.193\\%) &     214.704 &    181.355 (-15.532\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (m=1)} & original test set &         599.508 &      614.42 (+2.487\\%) &    578.395 &     598.135 (+3.413\\%) &    543.125 &     557.961 (+2.731\\%) &    607.586 &     681.44 (+12.155\\%) &      593.16 &      630.708 (+6.33\\%) \\\\\n",
      "                   & generated test set &          730.01 &    614.547 (-15.817\\%) &    686.014 &    600.295 (-12.495\\%) &    856.948 &    580.417 (-32.269\\%) &    773.443 &    659.565 (-14.724\\%) &     802.441 &    630.376 (-21.443\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (h=0.01)} & original test set &         599.508 &    675.136 (+12.615\\%) &    578.395 &     610.934 (+5.626\\%) &    543.125 &     553.251 (+1.864\\%) &    607.586 &    980.701 (+61.409\\%) &      593.16 &     662.76 (+11.734\\%) \\\\\n",
      "                   & generated test set &       28597.189 &  17923.248 (-37.325\\%) &  25665.182 &  14539.581 (-43.349\\%) &  24330.667 &  15835.171 (-34.917\\%) &  29048.515 &  17295.919 (-40.459\\%) &   28854.079 &  22039.445 (-23.618\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (f=0.01)} & original test set &         599.508 &      583.48 (-2.673\\%) &    578.395 &       577.47 (-0.16\\%) &    543.125 &      543.73 (+0.111\\%) &    607.586 &     612.072 (+0.738\\%) &      593.16 &     583.062 (-1.702\\%) \\\\\n",
      "                   & generated test set &         379.357 &    304.517 (-19.728\\%) &    369.606 &    300.902 (-18.589\\%) &    332.974 &    293.062 (-11.987\\%) &    395.106 &    321.762 (-18.563\\%) &      390.73 &     315.97 (-19.133\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_quarterly (h=0.01)} & original test set &         601.418 &    662.194 (+10.106\\%) &    593.796 &     645.512 (+8.709\\%) &    549.069 &     562.453 (+2.438\\%) &    586.797 &    659.522 (+12.394\\%) &     619.836 &     693.36 (+11.862\\%) \\\\\n",
      "                   & generated test set &       37976.754 &  27645.278 (-27.205\\%) &  33722.531 &   24824.17 (-26.387\\%) &  33184.391 &  27129.669 (-18.246\\%) &  34644.927 &   21912.904 (-36.75\\%) &   37737.281 &  31564.946 (-16.356\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_quarterly (m=-1)} & original test set &         601.418 &     612.979 (+1.922\\%) &    593.796 &     610.975 (+2.893\\%) &    549.069 &     586.319 (+6.784\\%) &    586.797 &     618.783 (+5.451\\%) &     619.836 &     693.07 (+11.815\\%) \\\\\n",
      "                   & generated test set &        1365.815 &    677.806 (-50.374\\%) &   1296.877 &    656.002 (-49.417\\%) &   1496.897 &    637.207 (-57.431\\%) &   1556.312 &      707.03 (-54.57\\%) &    1356.687 &    740.236 (-45.438\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_yearly (h=0.01)} & original test set &         856.154 &     941.741 (+9.997\\%) &    909.995 &   1082.577 (+18.965\\%) &    836.153 &      860.36 (+2.895\\%) &    882.914 &     969.431 (+9.799\\%) &     888.936 &     890.305 (+0.154\\%) \\\\\n",
      "                   & generated test set &       24146.394 &  20045.627 (-16.983\\%) &  26061.999 &   26058.511 (-0.013\\%) &  22951.076 &  14019.047 (-38.918\\%) &  24956.773 &   22856.016 (-8.418\\%) &    34480.49 &  28419.593 (-17.578\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(multirow=True, column_format=\"|ll|cc|cc|cc|cc|cc|\", multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e25a99b-9671-49ff-9de7-216a70959117",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "std_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "median_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "\n",
    "old_degen_average_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "old_degen_std_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "old_degen_median_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "\n",
    "per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood_degen\": []} for model_name in model_names}\n",
    "\n",
    "all_old = []\n",
    "all_generated = []\n",
    "all_ood_degen = []\n",
    "for dataset in scores_dict.keys():\n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        old_percentages = []\n",
    "        generated_percentages = []\n",
    "        ood_degen_percentages = []\n",
    "        for model in scores_dict[dataset]:\n",
    "            old_original_score = scores_dict[dataset][model][suffix][\"original model\"][\"orig\"]\n",
    "            old_generated_score = scores_dict[dataset][model][suffix][\"original model\"][\"ood\"]\n",
    "            new_original_score = scores_dict[dataset][model][suffix][\"new model\"][\"orig\"]\n",
    "            new_generated_score = scores_dict[dataset][model][suffix][\"new model\"][\"ood\"]\n",
    "            \n",
    "            old_percentage = (np.abs(old_original_score - new_original_score) / old_original_score) * 100\n",
    "            generated_percentage = (np.abs(old_generated_score - new_generated_score) / old_generated_score) * 100\n",
    "            ood_degeneration_percentage = (np.abs(old_original_score - old_generated_score) / old_original_score) * 100\n",
    "            \n",
    "            old_percentage = old_percentage if new_original_score >= old_original_score else -old_percentage\n",
    "            generated_percentage = generated_percentage if new_generated_score >= old_generated_score else -generated_percentage\n",
    "            ood_degeneration_percentage = ood_degeneration_percentage if old_generated_score >= old_original_score else -ood_degeneration_percentage\n",
    "            \n",
    "            old_percentages.append(old_percentage)\n",
    "            generated_percentages.append(generated_percentage)\n",
    "            ood_degen_percentages.append(ood_degeneration_percentage)\n",
    "            \n",
    "            per_model_percentages[model][\"original\"].append(old_percentage)\n",
    "            per_model_percentages[model][\"generated\"].append(generated_percentage)\n",
    "            per_model_percentages[model][\"ood_degen\"].append(ood_degeneration_percentage)\n",
    "            \n",
    "            all_old.append(old_percentage)\n",
    "            all_generated.append(generated_percentage)\n",
    "            all_ood_degen.append(ood_degeneration_percentage)\n",
    "\n",
    "        average_changes_per_transform[dataset][suffix] = {\"original test set\": np.mean(old_percentages), \"generated test set\": np.mean(generated_percentages)}\n",
    "        std_changes_per_transform[dataset][suffix] = {\"original test set\": np.std(old_percentages), \"generated test set\": np.std(generated_percentages)}\n",
    "        median_changes_per_transform[dataset][suffix] = {\"original test set\": np.median(old_percentages), \"generated test set\": np.median(generated_percentages)}\n",
    "        \n",
    "        old_degen_average_changes_per_transform[dataset][suffix] = np.mean(ood_degen_percentages)\n",
    "        old_degen_std_changes_per_transform[dataset][suffix] = np.std(ood_degen_percentages)\n",
    "        old_degen_median_changes_per_transform[dataset][suffix] = np.median(ood_degen_percentages)\n",
    "\n",
    "\n",
    "average_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names}\n",
    "std_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names}\n",
    "median_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names} \n",
    "for model in per_model_percentages:\n",
    "    average_per_model_percentages[model][\"original\"] = np.mean(per_model_percentages[model][\"original\"])\n",
    "    average_per_model_percentages[model][\"generated\"] = np.mean(per_model_percentages[model][\"generated\"])\n",
    "    average_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])\n",
    "    \n",
    "    std_per_model_percentages[model][\"original\"] = np.std(per_model_percentages[model][\"original\"])\n",
    "    std_per_model_percentages[model][\"generated\"] = np.std(per_model_percentages[model][\"generated\"])\n",
    "    std_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])\n",
    "    \n",
    "    median_per_model_percentages[model][\"original\"] = np.median(per_model_percentages[model][\"original\"])\n",
    "    median_per_model_percentages[model][\"generated\"] = np.median(per_model_percentages[model][\"generated\"])\n",
    "    median_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdce670-035b-4189-8c3a-7261e7422819",
   "metadata": {},
   "source": [
    "# Differences between the augmented and the old models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ad1171-9ce0-4d65-8231-c6cfa2fbfddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_nips\n",
      "\t (k=0.01)\n",
      "\t\tAverage percentage change on original test set:  13.157\n",
      "\t\tAverage percentage change on generated test set: -17.097\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  13.708\n",
      "\t\tStandard deviation of percentage change on generated test set: 9.91\n",
      "\n",
      "\t\tMedian percentage change on original test set:  8.994\n",
      "\t\tMedian percentage change on generated test set: -18.736\n",
      "electricity_nips\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  -2.199\n",
      "\t\tAverage percentage change on generated test set: -64.432\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  7.566\n",
      "\t\tStandard deviation of percentage change on generated test set: 15.019\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -0.74\n",
      "\t\tMedian percentage change on generated test set: -70.372\n",
      "electricity_nips\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  2.371\n",
      "\t\tAverage percentage change on generated test set: -63.757\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  10.232\n",
      "\t\tStandard deviation of percentage change on generated test set: 7.651\n",
      "\n",
      "\t\tMedian percentage change on original test set:  5.354\n",
      "\t\tMedian percentage change on generated test set: -62.572\n",
      "traffic_nips\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  51.253\n",
      "\t\tAverage percentage change on generated test set: -36.308\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  77.847\n",
      "\t\tStandard deviation of percentage change on generated test set: 13.544\n",
      "\n",
      "\t\tMedian percentage change on original test set:  7.231\n",
      "\t\tMedian percentage change on generated test set: -46.047\n",
      "traffic_nips\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  50.585\n",
      "\t\tAverage percentage change on generated test set: -8.607\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  74.316\n",
      "\t\tStandard deviation of percentage change on generated test set: 9.071\n",
      "\n",
      "\t\tMedian percentage change on original test set:  3.841\n",
      "\t\tMedian percentage change on generated test set: -2.98\n",
      "m4_hourly\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  13.646\n",
      "\t\tAverage percentage change on generated test set: -83.824\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  41.759\n",
      "\t\tStandard deviation of percentage change on generated test set: 1.939\n",
      "\n",
      "\t\tMedian percentage change on original test set:  16.298\n",
      "\t\tMedian percentage change on generated test set: -84.364\n",
      "m4_hourly\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  11.519\n",
      "\t\tAverage percentage change on generated test set: -75.285\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  39.06\n",
      "\t\tStandard deviation of percentage change on generated test set: 12.512\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -3.061\n",
      "\t\tMedian percentage change on generated test set: -78.259\n",
      "m4_daily\n",
      "\t (k=100)\n",
      "\t\tAverage percentage change on original test set:  -0.702\n",
      "\t\tAverage percentage change on generated test set: -49.846\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  1.862\n",
      "\t\tStandard deviation of percentage change on generated test set: 3.554\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -0.371\n",
      "\t\tMedian percentage change on generated test set: -51.754\n",
      "m4_weekly\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  5.13\n",
      "\t\tAverage percentage change on generated test set: -37.293\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  1.666\n",
      "\t\tStandard deviation of percentage change on generated test set: 16.236\n",
      "\n",
      "\t\tMedian percentage change on original test set:  4.012\n",
      "\t\tMedian percentage change on generated test set: -31.149\n",
      "m4_monthly\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  5.423\n",
      "\t\tAverage percentage change on generated test set: -19.35\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  3.635\n",
      "\t\tStandard deviation of percentage change on generated test set: 7.102\n",
      "\n",
      "\t\tMedian percentage change on original test set:  3.413\n",
      "\t\tMedian percentage change on generated test set: -15.817\n",
      "m4_monthly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  18.65\n",
      "\t\tAverage percentage change on generated test set: -35.933\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  21.744\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.784\n",
      "\n",
      "\t\tMedian percentage change on original test set:  11.734\n",
      "\t\tMedian percentage change on generated test set: -37.325\n",
      "m4_monthly\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  -0.737\n",
      "\t\tAverage percentage change on generated test set: -17.6\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  1.258\n",
      "\t\tStandard deviation of percentage change on generated test set: 2.839\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -0.16\n",
      "\t\tMedian percentage change on generated test set: -18.589\n",
      "m4_quarterly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  9.102\n",
      "\t\tAverage percentage change on generated test set: -24.989\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  3.578\n",
      "\t\tStandard deviation of percentage change on generated test set: 7.283\n",
      "\n",
      "\t\tMedian percentage change on original test set:  10.106\n",
      "\t\tMedian percentage change on generated test set: -26.387\n",
      "m4_quarterly\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  5.773\n",
      "\t\tAverage percentage change on generated test set: -51.446\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  3.486\n",
      "\t\tStandard deviation of percentage change on generated test set: 4.17\n",
      "\n",
      "\t\tMedian percentage change on original test set:  5.451\n",
      "\t\tMedian percentage change on generated test set: -50.374\n",
      "m4_yearly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  8.362\n",
      "\t\tAverage percentage change on generated test set: -16.382\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  6.549\n",
      "\t\tStandard deviation of percentage change on generated test set: 12.969\n",
      "\n",
      "\t\tMedian percentage change on original test set:  9.799\n",
      "\t\tMedian percentage change on generated test set: -16.983\n"
     ]
    }
   ],
   "source": [
    "for dataset in average_changes_per_transform:\n",
    "    for suffix in average_changes_per_transform[dataset]:\n",
    "        print(dataset)\n",
    "        print(f\"\\t{suffix_to_transformation[suffix]}\")\n",
    "        print(f\"\\t\\tAverage percentage change on original test set:  {np.round(average_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tAverage percentage change on generated test set: {np.round(average_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")\n",
    "        print()\n",
    "        print(f\"\\t\\tStandard deviation of percentage change on original test set:  {np.round(std_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tStandard deviation of percentage change on generated test set: {np.round(std_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")\n",
    "        print()\n",
    "        print(f\"\\t\\tMedian percentage change on original test set:  {np.round(median_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tMedian percentage change on generated test set: {np.round(median_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0403b60-72e8-4f70-a7ad-44db47fcf388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully-connected\n",
      "\tAverage percentage change on original test set:  7.769\n",
      "\tAverage percentage change on generated test set: -44.821\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  20.429\n",
      "\tStandard deviation of percentage change on generated test set: 26.714\n",
      "\n",
      "\tMedian percentage change on original test set:  3.979\n",
      "\tMedian percentage change on generated test set: -46.047\n",
      "LSTM\n",
      "\tAverage percentage change on original test set:  0.472\n",
      "\tAverage percentage change on generated test set: -37.544\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  15.584\n",
      "\tStandard deviation of percentage change on generated test set: 25.08\n",
      "\n",
      "\tMedian percentage change on original test set:  3.771\n",
      "\tMedian percentage change on generated test set: -43.349\n",
      "N-BEATS\n",
      "\tAverage percentage change on original test set:  0.216\n",
      "\tAverage percentage change on generated test set: -43.028\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  6.472\n",
      "\tStandard deviation of percentage change on generated test set: 23.797\n",
      "\n",
      "\tMedian percentage change on original test set:  1.864\n",
      "\tMedian percentage change on generated test set: -38.918\n",
      "TCN\n",
      "\tAverage percentage change on original test set:  24.102\n",
      "\tAverage percentage change on generated test set: -38.441\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  26.354\n",
      "\tStandard deviation of percentage change on generated test set: 23.382\n",
      "\n",
      "\tMedian percentage change on original test set:  12.155\n",
      "\tMedian percentage change on generated test set: -40.459\n",
      "Transformer\n",
      "\tAverage percentage change on original test set:  31.219\n",
      "\tAverage percentage change on generated test set: -36.883\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  65.84\n",
      "\tStandard deviation of percentage change on generated test set: 23.964\n",
      "\n",
      "\tMedian percentage change on original test set:  6.178\n",
      "\tMedian percentage change on generated test set: -23.248\n"
     ]
    }
   ],
   "source": [
    "for model in average_per_model_percentages:\n",
    "    print(model)\n",
    "    print(f\"\\tAverage percentage change on original test set:  {np.round(average_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tAverage percentage change on generated test set: {np.round(average_per_model_percentages[model]['generated'], 3)}\")\n",
    "    print()\n",
    "    print(f\"\\tStandard deviation of percentage change on original test set:  {np.round(std_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tStandard deviation of percentage change on generated test set: {np.round(std_per_model_percentages[model]['generated'], 3)}\")\n",
    "    print()\n",
    "    print(f\"\\tMedian percentage change on original test set:  {np.round(median_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tMedian percentage change on generated test set: {np.round(median_per_model_percentages[model]['generated'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8940f8cb-6079-44dd-ba1e-07f7f39f7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage change on original test set:  12.755\n",
      "Average percentage change on generated test set: -40.143\n",
      "\n",
      "Standard deviation of percentage change on original test set:  36.15\n",
      "Standard deviation of percentage change on generated test set: 24.821\n",
      "\n",
      "Median percentage change on original test set:  4.012\n",
      "Median percentage change on generated test set: -38.918\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average percentage change on original test set:  {np.round(np.mean(all_old), 3)}\")\n",
    "print(f\"Average percentage change on generated test set: {np.round(np.mean(all_generated), 3)}\")\n",
    "print()\n",
    "print(f\"Standard deviation of percentage change on original test set:  {np.round(np.std(all_old), 3)}\")\n",
    "print(f\"Standard deviation of percentage change on generated test set: {np.round(np.std(all_generated), 3)}\")\n",
    "print()\n",
    "print(f\"Median percentage change on original test set:  {np.round(np.median(all_old), 3)}\")\n",
    "print(f\"Median percentage change on generated test set: {np.round(np.median(all_generated), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536e207-c36a-44d3-9e6c-19833d2e14c7",
   "metadata": {},
   "source": [
    "# How much did the performance of the original models degenerate when faced with OOD data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e06aa9d-f515-41c5-9aeb-d72d32d35df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_nips\n",
      "\t (k=0.01)\n",
      "\t\tAverage OOD percentage change:  -22.185\n",
      "\t\tStandard deviation of OOD percentage change:  6.393\n",
      "\t\tMedian OOD percentage change:  -21.901\n",
      "electricity_nips\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  362.334\n",
      "\t\tStandard deviation of OOD percentage change:  113.103\n",
      "\t\tMedian OOD percentage change:  376.444\n",
      "electricity_nips\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  339.273\n",
      "\t\tStandard deviation of OOD percentage change:  96.103\n",
      "\t\tMedian OOD percentage change:  291.482\n",
      "traffic_nips\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  224.87\n",
      "\t\tStandard deviation of OOD percentage change:  90.27\n",
      "\t\tMedian OOD percentage change:  217.022\n",
      "traffic_nips\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  113.179\n",
      "\t\tStandard deviation of OOD percentage change:  84.075\n",
      "\t\tMedian OOD percentage change:  79.327\n",
      "m4_hourly\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  1124.734\n",
      "\t\tStandard deviation of OOD percentage change:  239.535\n",
      "\t\tMedian OOD percentage change:  1185.207\n",
      "m4_hourly\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  966.555\n",
      "\t\tStandard deviation of OOD percentage change:  283.628\n",
      "\t\tMedian OOD percentage change:  982.976\n",
      "m4_daily\n",
      "\t (k=100)\n",
      "\t\tAverage OOD percentage change:  2602.335\n",
      "\t\tStandard deviation of OOD percentage change:  72.593\n",
      "\t\tMedian OOD percentage change:  2576.482\n",
      "m4_weekly\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  139.104\n",
      "\t\tStandard deviation of OOD percentage change:  150.181\n",
      "\t\tMedian OOD percentage change:  188.729\n",
      "m4_monthly\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  32.147\n",
      "\t\tStandard deviation of OOD percentage change:  14.011\n",
      "\t\tMedian OOD percentage change:  27.298\n",
      "m4_monthly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  4566.522\n",
      "\t\tStandard deviation of OOD percentage change:  173.455\n",
      "\t\tMedian OOD percentage change:  4670.11\n",
      "m4_monthly\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  -36.122\n",
      "\t\tStandard deviation of OOD percentage change:  1.567\n",
      "\t\tMedian OOD percentage change:  -36.098\n",
      "m4_quarterly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  5905.957\n",
      "\t\tStandard deviation of OOD percentage change:  210.055\n",
      "\t\tMedian OOD percentage change:  5943.761\n",
      "m4_quarterly\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  140.446\n",
      "\t\tStandard deviation of OOD percentage change:  23.573\n",
      "\t\tMedian OOD percentage change:  127.099\n",
      "m4_yearly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  2926.926\n",
      "\t\tStandard deviation of OOD percentage change:  427.713\n",
      "\t\tMedian OOD percentage change:  2726.636\n"
     ]
    }
   ],
   "source": [
    "for dataset in average_changes_per_transform:\n",
    "    for suffix in average_changes_per_transform[dataset]:\n",
    "        print(dataset)\n",
    "        print(f\"\\t{suffix_to_transformation[suffix]}\")\n",
    "        print(f\"\\t\\tAverage OOD percentage change:  {np.round(old_degen_average_changes_per_transform[dataset][suffix], 3)}\")\n",
    "        print(f\"\\t\\tStandard deviation of OOD percentage change:  {np.round(old_degen_std_changes_per_transform[dataset][suffix], 3)}\")\n",
    "        print(f\"\\t\\tMedian OOD percentage change:  {np.round(old_degen_median_changes_per_transform[dataset][suffix], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beea9137-f1ff-4f4b-9ad9-89847f7026e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully-connected\n",
      "\tAverage percentage change on OOD:  1330.728\n",
      "\tStandard deviation of percentage change on OOD:  1330.728\n",
      "\tMedian percentage change on OOD:  1330.728\n",
      "LSTM\n",
      "\tAverage percentage change on OOD:  1214.487\n",
      "\tStandard deviation of percentage change on OOD:  1214.487\n",
      "\tMedian percentage change on OOD:  1214.487\n",
      "N-BEATS\n",
      "\tAverage percentage change on OOD:  1226.256\n",
      "\tStandard deviation of percentage change on OOD:  1226.256\n",
      "\tMedian percentage change on OOD:  1226.256\n",
      "TCN\n",
      "\tAverage percentage change on OOD:  1323.276\n",
      "\tStandard deviation of percentage change on OOD:  1323.276\n",
      "\tMedian percentage change on OOD:  1323.276\n",
      "Transformer\n",
      "\tAverage percentage change on OOD:  1367.279\n",
      "\tStandard deviation of percentage change on OOD:  1367.279\n",
      "\tMedian percentage change on OOD:  1367.279\n"
     ]
    }
   ],
   "source": [
    "for model in average_per_model_percentages:\n",
    "    print(model)\n",
    "    print(f\"\\tAverage percentage change on OOD:  {np.round(average_per_model_percentages[model]['ood'], 3)}\")\n",
    "    print(f\"\\tStandard deviation of percentage change on OOD:  {np.round(std_per_model_percentages[model]['ood'], 3)}\")\n",
    "    print(f\"\\tMedian percentage change on OOD:  {np.round(median_per_model_percentages[model]['ood'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be2ade73-4841-4250-9191-eb908be36494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage change on OOD: 1292.405\n",
      "Standard deviation of percentage change on OOD: 1807.938\n",
      "Median percentage change on OOD: 322.015\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average percentage change on OOD: {np.round(np.mean(all_ood_degen), 3)}\")\n",
    "print(f\"Standard deviation of percentage change on OOD: {np.round(np.std(all_ood_degen), 3)}\")\n",
    "print(f\"Median percentage change on OOD: {np.round(np.median(all_ood_degen), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b2a59-868c-4537-b306-4ef40d97c828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
