{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becd4163-1b5c-493b-be1a-f2537c6987ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f79f78a-72f9-4ff6-b6bc-86bab5b3474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/whatif/lib/python3.8/site-packages/gluonts/json.py:45: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bokeh.io.export import export_svg\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import log_cmap, linear_cmap\n",
    "from bokeh.util.hex import hexbin, cartesian_to_axial\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.loader import ValidationDataLoader\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.time_feature import (\n",
    "    HourOfDay,\n",
    "    DayOfWeek,\n",
    "    DayOfMonth,\n",
    "    DayOfYear,\n",
    "    MonthOfYear\n",
    ")\n",
    "from gluonts.torch.batchify import batchify\n",
    "from gluonts.transform import (\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    Chain,\n",
    "    InstanceSplitter,\n",
    "    ValidationSplitSampler\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.utils import get_model\n",
    "from src.utils.data_loading import load_features, load_score, load_test_data\n",
    "from src.utils.evaluation import score_batch\n",
    "from src.utils.features import decomps_and_features\n",
    "from src.utils.transformations import manipulate_trend_component, manipulate_seasonal_determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869f4000-c344-4000-b82c-fca9f05147d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generated_data(prefix, generated_test_datadir, len_test_data):\n",
    "    data = [0 for _ in range(len_test_data)]\n",
    "    for f in os.listdir(generated_test_datadir):\n",
    "        if f.startswith(prefix):\n",
    "            file_name = f.split(\".\")[0]  # slice off .npy from file name\n",
    "            ts_idx = int(file_name[len(prefix):])  # the remaining charachters after prefix is always the time series id\n",
    "            data[ts_idx] = np.load(os.path.join(generated_test_datadir, f))\n",
    "\n",
    "    data = np.array(data)  # [len(original_test), num_manipulations, 4]\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index, original_config, generated_datadir, len_test_data):\n",
    "    f_suffix = get_file_suffix(suffix, suffix_prefix_to_fname)\n",
    "    data_prefix = f\"ts_{f_suffix}\"\n",
    "    feature_prefix = f\"feat_{f_suffix}\"\n",
    "    gen_ts = load_generated_data(data_prefix, generated_datadir, len_test_data)\n",
    "    gen_features = load_generated_data(feature_prefix, generated_datadir, len_test_data)\n",
    "\n",
    "    idx = suffix_suffix_to_index[suffix[-3:]]\n",
    "    gen_ts = gen_ts[:, idx, :].reshape([-1, original_config[\"context_length\"] + original_config[\"prediction_length\"]])\n",
    "    gen_features = gen_features[:, idx, :].reshape([-1, 4])  # flatten the two first dimensions\n",
    "    return gen_ts, gen_features\n",
    "\n",
    "\n",
    "def create_gen_dataloader(generated_data, dataset, context_length, prediction_length, batch_size):\n",
    "    original_dataset = get_dataset(dataset)\n",
    "    \n",
    "    # nbeats doesn't do any covariates so we don't care that the starting points of forecasts are wrong here\n",
    "    list_data = [{\"start\": original[\"start\"], \"target\": generated, \"feat_static_cat\": original[\"feat_static_cat\"], \"item_id\": original[\"item_id\"]}\n",
    "                 for original, generated in zip(itertools.cycle(original_dataset.test), generated_data)]\n",
    "    generated_dataset = ListDataset(list_data, freq=original_dataset.metadata.freq)\n",
    "    \n",
    "    transformation = Chain([\n",
    "        AddObservedValuesIndicator(\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.OBSERVED_VALUES,\n",
    "        ),\n",
    "        AddTimeFeatures(\n",
    "            start_field=FieldName.START,\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.FEAT_TIME,\n",
    "            pred_length=prediction_length,\n",
    "            time_features=[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear(), MonthOfYear()]\n",
    "        ),\n",
    "        InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=ValidationSplitSampler(min_future=prediction_length),\n",
    "            past_length=context_length,\n",
    "            future_length=prediction_length,\n",
    "            time_series_fields=[FieldName.FEAT_TIME, FieldName.OBSERVED_VALUES]\n",
    "        )\n",
    "    ])\n",
    "    dataloader = ValidationDataLoader(\n",
    "        generated_dataset,\n",
    "        batch_size=batch_size,\n",
    "        stack_fn=batchify,\n",
    "        transform=transformation,\n",
    "        num_workers=1\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def organize_scores(all_scores, metric):\n",
    "    mape = []\n",
    "    smape = []\n",
    "    mase = []\n",
    "    seasonal_mase = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    for score in all_scores:\n",
    "        mape.append(score[0])\n",
    "        smape.append(score[1])\n",
    "        mase.append(score[2])\n",
    "        seasonal_mase.append(score[3])\n",
    "        mse.append(score[4])\n",
    "        mae.append(score[5])\n",
    "\n",
    "\n",
    "    mape = np.vstack(mape)\n",
    "    smape = np.vstack(smape)\n",
    "    mase = np.vstack(mase)\n",
    "    seasonal_mase = np.vstack(seasonal_mase)\n",
    "    mse = np.vstack(mse)\n",
    "    mae = np.vstack(mae)\n",
    "    \n",
    "    return {\"mape\": mape, \"smape\": smape, \"mase\": mase, \"seasonal_mase\": seasonal_mase, \"mse\": mse, \"mae\": mae}[metric]\n",
    "\n",
    "\n",
    "def get_scores(original_model, new_model, original_config, new_config, gen_ts, dataset, metric):\n",
    "\n",
    "    gen_dataloader = create_gen_dataloader(gen_ts, dataset, original_config[\"trainer_args\"][\"context_length\"],\n",
    "                                           original_config[\"trainer_args\"][\"prediction_length\"], original_config[\"trainer_args\"][\"batch_size\"])\n",
    "\n",
    "    original_gen_scores = []\n",
    "    new_gen_scores = []\n",
    "    original_model.eval()\n",
    "    new_model.eval()\n",
    "    for batch in tqdm(gen_dataloader):\n",
    "        original_preds = original_model.predict(batch)[:, :, 0]\n",
    "        new_preds = new_model.predict(batch)[:, :, 0]\n",
    "\n",
    "        context = batch[\"past_target\"].unsqueeze(dim=-1).numpy()\n",
    "        target = batch[\"future_target\"].numpy()\n",
    "\n",
    "        original_gen_scores.append(score_batch(target, original_preds, context, original_config[\"sp\"]))\n",
    "        new_gen_scores.append(score_batch(target, new_preds, context, new_config[\"sp\"]))\n",
    "\n",
    "    original_gen_scores = organize_scores(original_gen_scores, metric)\n",
    "    new_gen_scores = organize_scores(new_gen_scores, metric)\n",
    "    \n",
    "    return original_gen_scores, new_gen_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e434b0d4-002c-41d9-b3d9-7099b207442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_space(datadir):\n",
    "    train_features = load_features(datadir, train=True)\n",
    "    test_features = load_features(datadir, train=False)\n",
    "    scaler = StandardScaler()\n",
    "    norm_train_features = scaler.fit_transform(train_features)\n",
    "    norm_test_features = scaler.transform(test_features)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    train_pca_data = pca.fit_transform(norm_train_features)\n",
    "    test_pca_data = pca.transform(norm_test_features)\n",
    "    return pca, scaler, test_pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faaa44be-9e40-4c9a-bea9-b8340ca23989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_arr(scores, quantiles=None):\n",
    "    if quantiles is None:\n",
    "        quantiles = np.nanquantile(scores, [0.25, 0.75])\n",
    "    \n",
    "    low = scores < quantiles[0]\n",
    "    high = scores > quantiles[1]\n",
    "    medium = np.logical_and(~low, ~high)\n",
    "    \n",
    "    colors = np.empty_like(scores)\n",
    "    colors[low] = 0\n",
    "    colors[medium] = 1\n",
    "    colors[high] = 2\n",
    "    \n",
    "    return colors\n",
    "\n",
    "\n",
    "def color_bin(bins, pca_data, colors, column_name):\n",
    "    q, r = cartesian_to_axial(pca_data[:, 0], pca_data[:, 1], 0.1, \"pointytop\")\n",
    "    df = pd.DataFrame(dict(r=r, q=q))\n",
    "    groups = df.groupby([\"q\", \"r\"])\n",
    "    \n",
    "    for (q, r), indexes in groups.groups.items():\n",
    "        color = np.nanmean(colors[indexes])\n",
    "        bins.loc[(bins[\"q\"] == q) & (bins[\"r\"] == r), column_name] = color\n",
    "    \n",
    "    return bins\n",
    "\n",
    "\n",
    "def get_fig(title, xrange, yrange):\n",
    "    p = figure(title=title, tools=\"\", match_aspect=True, x_range=xrange, y_range=yrange)\n",
    "    p.output_backend = \"svg\"\n",
    "    p.title.align = \"center\"\n",
    "    p.grid.visible = False\n",
    "    return p\n",
    "\n",
    "\n",
    "def create_and_plot_hexbin(original_scores, new_scores, pca_data, figdir, dataset, suffix, model, metric, limits):\n",
    "    # create a seperate folder for each dataset and model\n",
    "    figdir = os.path.join(figdir, dataset, model)\n",
    "    if not os.path.isdir(figdir):\n",
    "        os.makedirs(figdir, exist_ok=True)\n",
    "    \n",
    "    # create hexbins\n",
    "    bins = hexbin(pca_data[:, 0], pca_data[:, 1], 0.1)\n",
    "    bins[\"original_colors\"] = np.nan\n",
    "    bins[\"new_colors\"] = np.nan\n",
    "    \n",
    "    orig_quantiles = np.nanquantile(original_scores, [0.25, 0.75])\n",
    "    original_colors = create_color_arr(original_scores, orig_quantiles)\n",
    "    new_colors = create_color_arr(new_scores, orig_quantiles)\n",
    "\n",
    "    bins = color_bin(bins, pca_data, original_colors, \"original_colors\")\n",
    "    bins = color_bin(bins, pca_data, new_colors, \"new_colors\")\n",
    "    \n",
    "    # plot original model\n",
    "    if limits is not None:\n",
    "        xrange = limits[\"xrange\"]\n",
    "        yrange = limits[\"yrange\"]\n",
    "    else:\n",
    "        xrange = None\n",
    "        yrange = None\n",
    "    \n",
    "    p = get_fig(f\"{model} trained with original training data\", xrange, yrange)\n",
    "    p.hex_tile(q=\"q\", r=\"r\", size=0.1, line_color=None, source=bins,\n",
    "                fill_color=linear_cmap(\"original_colors\", \"Viridis256\", min(bins.original_colors), max(bins.original_colors)))\n",
    "\n",
    "    export_svg(p, filename=os.path.join(figdir, f\"{dataset}_{suffix}_{model}_orig_{metric}_hexbin.svg\"))\n",
    "    \n",
    "    # plot new model\n",
    "    p = get_fig(f\"{model} trained with augmented training data\", xrange, yrange)\n",
    "    p.hex_tile(q=\"q\", r=\"r\", size=0.1, line_color=None, source=bins,\n",
    "                fill_color=linear_cmap(\"new_colors\", \"Viridis256\", min(bins.new_colors), max(bins.new_colors)))\n",
    "\n",
    "    export_svg(p, filename=os.path.join(figdir, f\"{dataset}_{suffix}_{model}_OOD_{metric}_hexbin.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8872f8-70f2-42bd-ae96-c95c88fb17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_suffix(suffix, suffix_prefix_to_fname):\n",
    "    for prefix in suffix_prefix_to_fname.keys():\n",
    "        if suffix.startswith(prefix):\n",
    "            return suffix_prefix_to_fname[prefix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f2b74d-0be1-4e8e-adc7-9a6c11b2fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataset, config):\n",
    "    test_data = load_test_data(dataset, config[\"context_length\"] + config[\"prediction_length\"])\n",
    "    \n",
    "    trend_str_inc_ts = []\n",
    "    trend_str_dec_ts = []\n",
    "    trend_lin_inc_ts = []\n",
    "    trend_lin_dec_ts = []\n",
    "    trend_slope_inc_ts = []\n",
    "    trend_slope_dec_ts = []\n",
    "    seas_str_inc_ts = []\n",
    "    seas_str_dec_ts = []\n",
    "\n",
    "    trend_str_inc_feat = []\n",
    "    trend_str_dec_feat = []\n",
    "    trend_lin_inc_feat = []\n",
    "    trend_lin_dec_feat = []\n",
    "    trend_slope_inc_feat = []\n",
    "    trend_slope_dec_feat = []\n",
    "    seas_str_inc_feat = []\n",
    "    seas_str_dec_feat = []\n",
    "    for ts in tqdm(test_data):\n",
    "        decomp = decomps_and_features([ts], config[\"sp\"])[0][0]\n",
    "        \n",
    "        inc_str = manipulate_trend_component(decomp.trend, f=100, g=1, h=1, m=0) + decomp.seasonal + decomp.resid\n",
    "        dec_str = manipulate_trend_component(decomp.trend, f=0.01, g=1, h=1, m=0) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        inc_lin = manipulate_trend_component(decomp.trend, f=1, g=1, h=100, m=0) + decomp.seasonal + decomp.resid\n",
    "        dec_lin = manipulate_trend_component(decomp.trend, f=1, g=1, h=0.01, m=0) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        inc_slope = manipulate_trend_component(decomp.trend, f=1, g=1, h=1, m=-1) + decomp.seasonal + decomp.resid\n",
    "        dec_slope = manipulate_trend_component(decomp.trend, f=1, g=1, h=1, m=1) + decomp.seasonal + decomp.resid\n",
    "        \n",
    "        generated_ts = [inc_str, dec_str, inc_lin, dec_lin, inc_slope, dec_slope]\n",
    "        if config[\"sp\"] > 1:\n",
    "            inc_seas = manipulate_seasonal_determination(decomp.seasonal, k=100) + decomp.trend + decomp.resid\n",
    "            dec_seas = manipulate_seasonal_determination(decomp.seasonal, k=0.01) + decomp.trend + decomp.resid\n",
    "            generated_ts.extend([inc_seas, dec_seas])\n",
    "            \n",
    "        _, features = decomps_and_features(generated_ts, config[\"sp\"])\n",
    "        \n",
    "        trend_str_inc_ts.append(inc_str)\n",
    "        trend_str_dec_ts.append(dec_str)\n",
    "        trend_lin_inc_ts.append(inc_lin)\n",
    "        trend_lin_dec_ts.append(dec_lin)\n",
    "        trend_slope_inc_ts.append(inc_slope)\n",
    "        trend_slope_dec_ts.append(dec_slope)\n",
    "        \n",
    "        trend_str_inc_feat.append(features[0])\n",
    "        trend_str_dec_feat.append(features[1])\n",
    "        trend_lin_inc_feat.append(features[2])\n",
    "        trend_lin_dec_feat.append(features[3])\n",
    "        trend_slope_inc_feat.append(features[4])\n",
    "        trend_slope_dec_feat.append(features[5])\n",
    "        \n",
    "        if config[\"sp\"] > 1:\n",
    "            seas_str_inc_ts.append(inc_seas)\n",
    "            seas_str_dec_ts.append(dec_seas)\n",
    "            seas_str_inc_feat.append(features[6])\n",
    "            seas_str_dec_feat.append(features[7])\n",
    "    \n",
    "    trend_str_inc_ts = np.array(trend_str_inc_ts)\n",
    "    trend_str_dec_ts = np.array(trend_str_dec_ts)\n",
    "    trend_lin_inc_ts = np.array(trend_lin_inc_ts)\n",
    "    trend_lin_dec_ts = np.array(trend_lin_dec_ts)\n",
    "    trend_slope_inc_ts = np.array(trend_slope_inc_ts)\n",
    "    trend_slope_dec_ts = np.array(trend_slope_dec_ts)\n",
    "    seas_str_inc_ts = np.array(seas_str_inc_ts)\n",
    "    seas_str_dec_ts = np.array(seas_str_dec_ts)\n",
    "    \n",
    "    trend_str_inc_feat = np.array(trend_str_inc_feat)\n",
    "    trend_str_dec_feat = np.array(trend_str_dec_feat)\n",
    "    trend_lin_inc_feat = np.array(trend_lin_inc_feat)\n",
    "    trend_lin_dec_feat = np.array(trend_lin_dec_feat)\n",
    "    trend_slope_inc_feat = np.array(trend_slope_inc_feat)\n",
    "    trend_slope_dec_feat = np.array(trend_slope_dec_feat)\n",
    "    seas_str_inc_feat = np.array(seas_str_inc_feat)\n",
    "    seas_str_dec_feat = np.array(seas_str_dec_feat)\n",
    "    \n",
    "    ts_dict = {\"trend_str_inc\": trend_str_inc_ts, \"trend_str_dec\": trend_str_dec_ts,\n",
    "               \"lin_inc\": trend_lin_inc_ts, \"lin_dec\": trend_lin_dec_ts,\n",
    "               \"slope_inc\": trend_slope_inc_ts, \"slope_dec\": trend_slope_dec_ts,\n",
    "               \"seas_inc\": seas_str_inc_ts, \"seas_dec\": seas_str_dec_ts}\n",
    "    \n",
    "    feat_dict = {\"trend_str_inc\": trend_str_inc_feat, \"trend_str_dec\": trend_str_dec_feat,\n",
    "                \"lin_inc\": trend_lin_inc_feat, \"lin_dec\": trend_lin_dec_feat,\n",
    "                \"slope_inc\": trend_slope_inc_feat, \"slope_dec\": trend_slope_dec_feat,\n",
    "                \"seas_inc\": seas_str_inc_feat, \"seas_dec\": seas_str_dec_feat}\n",
    "    \n",
    "    return ts_dict, feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e208d084-ef9d-47f7-99ee-f34ce8fa42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"smape\"\n",
    "create_plots = True\n",
    "models = [\"feedforward\", \"seq2seq\", \"nbeats_g\", \"tcn\", \"transformer\"]\n",
    "model_names = [\"Fully-connected\", \"LSTM\", \"N-BEATS\", \"TCN\", \"Transformer\"]\n",
    "\n",
    "dataset_suffixes = {\n",
    "    \"electricity_nips\": [\"seas_dec\", \"slope_dec\", \"slope_inc\"],\n",
    "    \"traffic_nips\": [\"slope_inc\", \"trend_str_dec\"],  # \"seas_dec\", \"slope_dec\", \n",
    "    \"m4_hourly\": [\"slope_dec\", \"slope_inc\"],  # \"seas_dec\"\n",
    "    \"m4_daily\": [\"seas_inc\"],\n",
    "    \"m4_weekly\": [\"trend_str_dec\"],  # \"slope_dec\", \"slope_inc\", \n",
    "    \"m4_monthly\": [\"slope_inc\", \"lin_dec\", \"trend_str_dec\"],  # \"seas_dec\", \"slope_dec\", \n",
    "    \"m4_quarterly\": [\"lin_dec\", \"slope_dec\"],  # \"seas_dec\", \"seas_inc\", \n",
    "    \"m4_yearly\": [\"lin_dec\"]  # \"slope_dec\", \"slope_inc\"\n",
    "}\n",
    "plot_limits = {\n",
    "    \"electricity_nips\": {\"slope_dec\": {\"xrange\": [-5, 6], \"yrange\": [-8, 6]}, \"slope_inc\": {\"xrange\": [-3, 8], \"yrange\": [-3, 8]}},\n",
    "    \"traffic_nips\": {\"lin_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}},\n",
    "    \"m4_hourly\": {\"slope_dec\": {\"xrange\": [-10, 5], \"yrange\": [-12, 6]}},\n",
    "    \"m4_daily\": {},\n",
    "    \"m4_weekly\": {},\n",
    "    \"m4_monthly\": {\"lin_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 5]}, \"slope_dec\": {\"xrange\": [-5, 8], \"yrange\": [-5, 8]}, \"trend_str_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 8]}},\n",
    "    \"m4_quarterly\": {\"lin_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}, \"slope_dec\": {\"xrange\": [-4, 5], \"yrange\": [-4, 5]}},\n",
    "    \"m4_yearly\": {\"slope_dec\": {\"xrange\": [-10, 10], \"yrange\": [-15, 5]}, \"slope_inc\": {\"xrange\": [-10, 10], \"yrange\": [-5, 15]}, \"lin_dec\": {\"xrange\": [-5, 5], \"yrange\": [-5, 5]}},\n",
    "}\n",
    "suffix_prefix_to_fname = {\"seas\": \"seasonal_str\", \"slope\": \"trend_slope\", \"lin\": \"trend_lin\", \"trend_str\": \"trend_str\"}\n",
    "suffix_suffix_to_index = {\"inc\": 98, \"dec\": -1}\n",
    "\n",
    "figdir = \"figures/OOD\"\n",
    "if not os.path.isdir(figdir):\n",
    "    os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5c198e-4c88-4c43-82e6-babff624feea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for electricity_nips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  3.94it/s]\n",
      "6it [00:02,  2.92it/s]\n",
      "6it [00:01,  3.07it/s]\n",
      "6it [00:03,  1.60it/s]\n",
      "6it [00:02,  2.05it/s]\n",
      "6it [00:01,  4.38it/s]\n",
      "6it [00:02,  2.92it/s]\n",
      "6it [00:01,  3.17it/s]\n",
      "6it [00:03,  1.60it/s]\n",
      "6it [00:02,  2.02it/s]\n",
      "6it [00:01,  4.26it/s]\n",
      "6it [00:02,  2.89it/s]\n",
      "6it [00:01,  3.17it/s]\n",
      "6it [00:03,  1.58it/s]\n",
      "6it [00:02,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for traffic_nips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:03,  3.85it/s]\n",
      "14it [00:05,  2.67it/s]\n",
      "14it [00:04,  2.85it/s]\n",
      "14it [00:09,  1.50it/s]\n",
      "14it [00:07,  1.79it/s]\n",
      "14it [00:03,  3.88it/s]\n",
      "14it [00:04,  2.92it/s]\n",
      "14it [00:04,  2.83it/s]\n",
      "14it [00:09,  1.47it/s]\n",
      "14it [00:07,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_hourly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.41it/s]\n",
      "1it [00:00,  3.40it/s]\n",
      "1it [00:00,  3.85it/s]\n",
      "1it [00:00,  1.55it/s]\n",
      "1it [00:00,  2.86it/s]\n",
      "1it [00:00,  5.74it/s]\n",
      "1it [00:00,  3.85it/s]\n",
      "1it [00:00,  4.27it/s]\n",
      "1it [00:00,  1.85it/s]\n",
      "1it [00:00,  2.98it/s]\n",
      "  6%|▌         | 243/4227 [00:00<00:01, 2426.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_daily...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4227/4227 [00:02<00:00, 1464.68it/s]\n",
      "100%|██████████| 4227/4227 [03:16<00:00, 21.48it/s]\n",
      "9it [00:00,  9.14it/s]\n",
      "9it [00:01,  6.99it/s]\n",
      "9it [00:01,  5.18it/s]\n",
      "9it [00:01,  5.66it/s]\n",
      "9it [00:01,  4.88it/s]\n",
      " 33%|███▎      | 119/359 [00:00<00:00, 1187.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_weekly...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:00<00:00, 1261.42it/s]\n",
      "100%|██████████| 359/359 [00:11<00:00, 31.24it/s]\n",
      "1it [00:00,  8.54it/s]\n",
      "1it [00:00,  7.24it/s]\n",
      "1it [00:00,  5.38it/s]\n",
      "1it [00:00,  6.30it/s]\n",
      "1it [00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_monthly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:12,  7.54it/s]\n",
      "94it [00:16,  5.64it/s]\n",
      "94it [00:20,  4.61it/s]\n",
      "94it [00:21,  4.36it/s]\n",
      "94it [00:22,  4.25it/s]\n",
      "94it [00:12,  7.67it/s]\n",
      "94it [00:16,  5.64it/s]\n",
      "94it [00:20,  4.57it/s]\n",
      "94it [00:21,  4.38it/s]\n",
      "94it [00:21,  4.28it/s]\n",
      "94it [00:12,  7.75it/s]\n",
      "94it [00:16,  5.65it/s]\n",
      "94it [00:20,  4.58it/s]\n",
      "94it [00:21,  4.37it/s]\n",
      "94it [00:21,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_quarterly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:04, 10.56it/s]\n",
      "47it [00:05,  8.19it/s]\n",
      "47it [00:08,  5.32it/s]\n",
      "47it [00:06,  7.27it/s]\n",
      "47it [00:07,  6.60it/s]\n",
      "47it [00:04, 10.31it/s]\n",
      "47it [00:06,  7.75it/s]\n",
      "47it [00:08,  5.30it/s]\n",
      "47it [00:06,  7.60it/s]\n",
      "47it [00:07,  6.11it/s]\n",
      "  1%|          | 250/23000 [00:00<00:09, 2495.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores and creating plots for m4_yearly...\n",
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23000/23000 [00:09<00:00, 2315.77it/s]\n",
      "100%|██████████| 23000/23000 [12:25<00:00, 30.86it/s]\n",
      "45it [00:05,  8.57it/s]\n",
      "45it [00:06,  7.25it/s]\n",
      "45it [00:09,  4.65it/s]\n",
      "45it [00:06,  6.88it/s]\n",
      "45it [00:07,  6.06it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {key: {} for key in dataset_suffixes.keys()}\n",
    "\n",
    "for dataset in dataset_suffixes.keys():\n",
    "    print(f\"Calculating scores and creating plots for {dataset}...\")\n",
    "    datadir = f\"data/{dataset}\"\n",
    "    generated_datadir = os.path.join(f\"/datadrive2/whatif/{dataset}\", \"generated\", \"test\")\n",
    "    \n",
    "    #create instance space\n",
    "    pca, scaler, test_pca_data = create_instance_space(datadir)\n",
    "    \n",
    "    # load the config and score of some random model to get metadata\n",
    "    original_experiment_dir = f\"experiments/{dataset}/nbeats_g\"\n",
    "    with open(os.path.join(original_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "        original_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    original_scores = load_score(original_experiment_dir, metric)\n",
    "    \n",
    "    if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "        generated_data, generated_features = generate_data(dataset, original_config)\n",
    "    \n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        # load data and features\n",
    "        if suffix == \"all\":\n",
    "            gen_ts = []\n",
    "            gen_features = []\n",
    "            for suffix in dataset_suffixes[dataset]:\n",
    "                if suffix == \"all\":\n",
    "                    continue\n",
    "                \n",
    "                if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "                    gen_ts_suffix = generated_data[suffix]\n",
    "                    gen_features_suffix = generated_features[suffix]\n",
    "                else:\n",
    "                    gen_ts_suffix, gen_features_suffix = load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index,\n",
    "                                                                                          original_config, generated_datadir, original_scores.shape[0])\n",
    "                gen_ts.append(gen_ts_suffix)\n",
    "                gen_features.append(gen_features_suffix)\n",
    "\n",
    "            gen_ts = np.vstack(gen_ts)\n",
    "            gen_features = np.vstack(gen_features)\n",
    "        else:\n",
    "            if dataset in [\"m4_daily\", \"m4_weekly\", \"m4_yearly\"]:\n",
    "                gen_ts = generated_data[suffix]\n",
    "                gen_features = generated_features[suffix]\n",
    "            else:\n",
    "                gen_ts, gen_features = load_generated_features_and_data(suffix, suffix_prefix_to_fname, suffix_suffix_to_index,\n",
    "                                                                        original_config, generated_datadir, original_scores.shape[0])\n",
    "\n",
    "        for model, name in zip(models, model_names):\n",
    "            # load original model\n",
    "            original_experiment_dir = f\"experiments/{dataset}/{model}\"\n",
    "            with open(os.path.join(original_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "                original_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "            original_model = get_model(original_config[\"model_name\"])(**original_config[\"model_args\"], device=device, path=original_config[\"path\"]).to(device)\n",
    "            original_model.load_state_dict(torch.load(os.path.join(original_config[\"path\"], \"model.pth\")))\n",
    "            original_scores = load_score(original_experiment_dir, metric)\n",
    "        \n",
    "            # load new model\n",
    "            new_experiment_dir = f\"experiments/{dataset}/{model}_gen_{suffix}\"\n",
    "            with open(os.path.join(new_experiment_dir, \"config.yaml\"), \"r\") as f:\n",
    "                new_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "                \n",
    "            new_model = get_model(new_config[\"model_name\"])(**new_config[\"model_args\"], device=device, path=new_config[\"path\"]).to(device)\n",
    "            new_model.load_state_dict(torch.load(os.path.join(new_config[\"path\"], \"model.pth\")))\n",
    "            new_scores = load_score(new_experiment_dir, metric)\n",
    "            \n",
    "            # evaluate models on OOD test data\n",
    "            original_gen_scores, new_gen_scores = get_scores(original_model, new_model, original_config, new_config, gen_ts, dataset, metric)\n",
    "            \n",
    "            if name not in scores_dict[dataset].keys():\n",
    "                scores_dict[dataset][name] = {suffix: {\"original model\": {\"orig\": np.nanmean(original_scores), \"ood\": np.nanmean(original_gen_scores)},\n",
    "                                                       \"new model\": {\"orig\": np.nanmean(new_scores), \"ood\": np.nanmean(new_gen_scores)}}}\n",
    "            else:\n",
    "                scores_dict[dataset][name][suffix] = {\"original model\": {\"orig\": np.nanmean(original_scores), \"ood\": np.nanmean(original_gen_scores)},\n",
    "                                                      \"new model\": {\"orig\": np.nanmean(new_scores), \"ood\": np.nanmean(new_gen_scores)}}\n",
    "            \n",
    "            # concatenate scores on original test data and ood test, and calculate mean per time series\n",
    "            original_scores_concat = np.concatenate([original_scores, original_gen_scores], axis=0)\n",
    "            new_scores_concat = np.concatenate([new_scores, new_gen_scores], axis=0)\n",
    "            original_ts_scores = np.nanmean(original_scores_concat, axis=-1)\n",
    "            new_ts_scores = np.nanmean(new_scores_concat, axis=-1)\n",
    "            \n",
    "            # transform generated features to instance space and concatenate with original test data\n",
    "            norm_gen_features = scaler.transform(gen_features)\n",
    "            gen_pca_data = pca.transform(norm_gen_features)\n",
    "            concatenated_pca_data = np.concatenate([test_pca_data, gen_pca_data], axis=0)\n",
    "            \n",
    "            if create_plots:\n",
    "                limits = plot_limits[dataset].get(suffix)\n",
    "                create_and_plot_hexbin(original_ts_scores, new_ts_scores, concatenated_pca_data, figdir, dataset, suffix, name, metric, limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d0ca3e-7e0a-4bb9-87d1-50742cdb6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_to_transformation = {\"trend_str_inc\": \" (f=100)\", \"trend_str_dec\": \" (f=0.01)\",\n",
    "                            \"slope_inc\": \" (m=1)\", \"slope_dec\": \" (m=-1)\",\n",
    "                            \"lin_inc\": \" (h=100)\", \"lin_dec\": \" (h=0.01)\",\n",
    "                            \"seas_inc\": \" (k=100)\", \"seas_dec\": \" (k=0.01)\"}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for dataset in scores_dict.keys():\n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        # create a multi index for each transformation in the dataset, with one row for original data and one row for generated data\n",
    "        row_name = dataset + suffix_to_transformation[suffix]\n",
    "        tuples = [(row_name, \"original test set\"), (row_name, (\"generated test set\"))]\n",
    "        index = pd.MultiIndex.from_tuples(tuples)\n",
    "        \n",
    "        columns = []\n",
    "        old_original_scores = []\n",
    "        new_original_scores = []\n",
    "        old_generated_scores = []\n",
    "        new_generated_scores = []\n",
    "        for model in scores_dict[dataset]:\n",
    "            old_model_col = (model, \"old\")\n",
    "            new_model_col =  (model, \"augmented\")\n",
    "            columns.append(old_model_col)\n",
    "            columns.append(new_model_col)\n",
    "            \n",
    "            old_original_scores.append(scores_dict[dataset][model][suffix][\"original model\"][\"orig\"])\n",
    "            old_generated_scores.append(scores_dict[dataset][model][suffix][\"original model\"][\"ood\"])\n",
    "            new_original_scores.append(scores_dict[dataset][model][suffix][\"new model\"][\"orig\"])\n",
    "            new_generated_scores.append(scores_dict[dataset][model][suffix][\"new model\"][\"ood\"])\n",
    "        \n",
    "        \n",
    "        zipped_original = []\n",
    "        for old, new in zip(old_original_scores, new_original_scores):\n",
    "            zipped_original.append(np.round(old, 3))\n",
    "            \n",
    "            percentage = np.round((np.abs(old - new) / old) * 100, 3)\n",
    "            percentage_str = \"+\" + str(percentage) if new >= old else \"-\" + str(percentage)\n",
    "            new = f\"{np.round(new, 3)} ({percentage_str}%)\"\n",
    "            zipped_original.append(new)\n",
    "            \n",
    "            \n",
    "        zipped_generated = []\n",
    "        for old, new in zip(old_generated_scores, new_generated_scores):\n",
    "            zipped_generated.append(np.round(old, 3))\n",
    "            \n",
    "            percentage = np.round((np.abs(old - new) / old) * 100, 3)\n",
    "            percentage_str = \"+\" + str(percentage) if new >= old else \"-\" + str(percentage)\n",
    "            new = f\"{np.round(new, 3)} ({percentage_str}%)\"\n",
    "            zipped_generated.append(new)\n",
    "        \n",
    "        suffix_df = pd.DataFrame(np.vstack([zipped_original, zipped_generated]), columns=columns)\n",
    "        suffix_df.index = index\n",
    "        suffix_df.columns = pd.MultiIndex.from_tuples(suffix_df.columns)\n",
    "        df = pd.concat([df, suffix_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dfc06b-ddc8-4dbe-b937-30e8fd1e9378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fully-connected</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSTM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">N-BEATS</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TCN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Transformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "      <th>old</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (k=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.121</td>\n",
       "      <td>0.138 (+14.624%)</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.121 (+4.182%)</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.099 (+3.003%)</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.14 (+21.752%)</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.117 (+5.53%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.087</td>\n",
       "      <td>0.069 (-20.622%)</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.097 (-11.105%)</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.062 (-27.453%)</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.084 (-10.907%)</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.079 (-16.837%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.121</td>\n",
       "      <td>0.112 (-7.42%)</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.115 (-1.041%)</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.097 (+1.202%)</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.122 (+5.976%)</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.114 (+2.886%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.372</td>\n",
       "      <td>0.535 (-60.974%)</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.079 (-22.473%)</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.522 (-36.667%)</td>\n",
       "      <td>1.183</td>\n",
       "      <td>0.695 (-41.278%)</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.617 (-51.666%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">electricity_nips (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.121</td>\n",
       "      <td>0.109 (-9.738%)</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.122 (+4.889%)</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.097 (+1.374%)</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.127 (+10.712%)</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.12 (+8.19%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.194</td>\n",
       "      <td>0.053 (-72.449%)</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.109 (-51.589%)</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.056 (-55.038%)</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.08 (-60.759%)</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.081 (-51.553%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">traffic_nips (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.173 (+2.69%)</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.201 (+8.111%)</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.095 (+6.914%)</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.224 (+31.106%)</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.563 (+172.249%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.067 (-57.065%)</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.204 (-19.94%)</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.055 (-55.549%)</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.147 (-55.149%)</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.287 (-29.751%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">traffic_nips (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.159 (-5.34%)</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.173 (-6.947%)</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.095 (+6.851%)</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.398 (+132.73%)</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.555 (+168.215%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.257</td>\n",
       "      <td>0.239 (-6.942%)</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.432 (-17.654%)</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.219 (-2.309%)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.337 (-3.588%)</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.55 (-14.414%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_hourly (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.178 (+6.736%)</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.14 (-2.725%)</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.146 (+31.405%)</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.286 (+82.92%)</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.198 (+13.727%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.593</td>\n",
       "      <td>0.478 (-69.983%)</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0.547 (-66.73%)</td>\n",
       "      <td>1.617</td>\n",
       "      <td>0.449 (-72.229%)</td>\n",
       "      <td>1.639</td>\n",
       "      <td>0.661 (-59.711%)</td>\n",
       "      <td>1.628</td>\n",
       "      <td>0.603 (-62.939%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_hourly (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.172 (+2.922%)</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.168 (+16.594%)</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.121 (+9.093%)</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.176 (+12.257%)</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.176 (+1.21%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.065 (-74.784%)</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.083 (-78.519%)</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.048 (-82.628%)</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.131 (-63.312%)</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.078 (-77.327%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_daily (k=100)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.031 (+2.151%)</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03 (-0.853%)</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03 (-0.694%)</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031 (-3.88%)</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03 (-1.035%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.385 (-42.231%)</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.37 (-44.423%)</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.381 (-42.984%)</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.389 (-43.815%)</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.42 (-37.394%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_weekly (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.085 (+1.201%)</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.082 (-0.596%)</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.093 (+4.635%)</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.093 (+13.034%)</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.093 (+14.638%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.112 (-51.666%)</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.118 (-37.729%)</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.05 (-21.927%)</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.143 (-42.339%)</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.053 (-11.754%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (m=1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.137</td>\n",
       "      <td>0.14 (+1.834%)</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.137 (+2.401%)</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.131 (+2.114%)</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.153 (+9.471%)</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.143 (+4.71%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.063 (-15.041%)</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.061 (-12.525%)</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.06 (-28.639%)</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.066 (-15.843%)</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.064 (-21.745%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.137</td>\n",
       "      <td>0.155 (+13.037%)</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.14 (+4.957%)</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.13 (+1.714%)</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.221 (+58.13%)</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.151 (+10.565%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.141</td>\n",
       "      <td>0.841 (-26.304%)</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.773 (-28.998%)</td>\n",
       "      <td>1.189</td>\n",
       "      <td>0.792 (-33.374%)</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.772 (-33.618%)</td>\n",
       "      <td>1.183</td>\n",
       "      <td>0.983 (-16.875%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_monthly (f=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.137</td>\n",
       "      <td>0.136 (-0.759%)</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.134 (+0.367%)</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.128 (-0.29%)</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.143 (+2.81%)</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.136 (-0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.081 (-15.968%)</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.08 (-15.113%)</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.079 (-10.894%)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085 (-14.66%)</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.083 (-15.588%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_quarterly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.118 (+11.967%)</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.113 (+8.295%)</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.101 (+1.924%)</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.116 (+11.484%)</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.121 (+9.703%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.187</td>\n",
       "      <td>0.984 (-17.044%)</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.948 (-16.954%)</td>\n",
       "      <td>1.292</td>\n",
       "      <td>1.015 (-21.447%)</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.868 (-27.146%)</td>\n",
       "      <td>1.255</td>\n",
       "      <td>1.074 (-14.451%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_quarterly (m=-1)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.112 (+6.48%)</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.112 (+7.411%)</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.109 (+10.157%)</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.117 (+12.858%)</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.122 (+10.957%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.201</td>\n",
       "      <td>0.616 (-48.721%)</td>\n",
       "      <td>1.154</td>\n",
       "      <td>0.592 (-48.666%)</td>\n",
       "      <td>1.318</td>\n",
       "      <td>0.578 (-56.152%)</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.638 (-51.246%)</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.636 (-45.949%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">m4_yearly (h=0.01)</th>\n",
       "      <th>original test set</th>\n",
       "      <td>0.138</td>\n",
       "      <td>0.154 (+11.069%)</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.166 (+17.483%)</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.146 (+7.004%)</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.157 (+13.041%)</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.145 (+1.626%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated test set</th>\n",
       "      <td>1.146</td>\n",
       "      <td>1.037 (-9.501%)</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.077 (-5.575%)</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.908 (-23.079%)</td>\n",
       "      <td>1.119</td>\n",
       "      <td>0.964 (-13.807%)</td>\n",
       "      <td>1.326</td>\n",
       "      <td>1.093 (-17.576%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Fully-connected  \\\n",
       "                                                         old   \n",
       "electricity_nips (k=0.01) original test set            0.121   \n",
       "                          generated test set           0.087   \n",
       "electricity_nips (m=-1)   original test set            0.121   \n",
       "                          generated test set           1.372   \n",
       "electricity_nips (m=1)    original test set            0.121   \n",
       "                          generated test set           0.194   \n",
       "traffic_nips (m=1)        original test set            0.168   \n",
       "                          generated test set           0.156   \n",
       "traffic_nips (f=0.01)     original test set            0.168   \n",
       "                          generated test set           0.257   \n",
       "m4_hourly (m=-1)          original test set            0.167   \n",
       "                          generated test set           1.593   \n",
       "m4_hourly (m=1)           original test set            0.167   \n",
       "                          generated test set           0.259   \n",
       "m4_daily (k=100)          original test set             0.03   \n",
       "                          generated test set           0.667   \n",
       "m4_weekly (f=0.01)        original test set            0.084   \n",
       "                          generated test set           0.232   \n",
       "m4_monthly (m=1)          original test set            0.137   \n",
       "                          generated test set           0.074   \n",
       "m4_monthly (h=0.01)       original test set            0.137   \n",
       "                          generated test set           1.141   \n",
       "m4_monthly (f=0.01)       original test set            0.137   \n",
       "                          generated test set           0.096   \n",
       "m4_quarterly (h=0.01)     original test set            0.105   \n",
       "                          generated test set           1.187   \n",
       "m4_quarterly (m=-1)       original test set            0.105   \n",
       "                          generated test set           1.201   \n",
       "m4_yearly (h=0.01)        original test set            0.138   \n",
       "                          generated test set           1.146   \n",
       "\n",
       "                                                                 LSTM  \\\n",
       "                                                     augmented    old   \n",
       "electricity_nips (k=0.01) original test set   0.138 (+14.624%)  0.116   \n",
       "                          generated test set  0.069 (-20.622%)  0.109   \n",
       "electricity_nips (m=-1)   original test set     0.112 (-7.42%)  0.116   \n",
       "                          generated test set  0.535 (-60.974%)  1.392   \n",
       "electricity_nips (m=1)    original test set    0.109 (-9.738%)  0.116   \n",
       "                          generated test set  0.053 (-72.449%)  0.226   \n",
       "traffic_nips (m=1)        original test set     0.173 (+2.69%)  0.186   \n",
       "                          generated test set  0.067 (-57.065%)  0.255   \n",
       "traffic_nips (f=0.01)     original test set     0.159 (-5.34%)  0.186   \n",
       "                          generated test set   0.239 (-6.942%)  0.524   \n",
       "m4_hourly (m=-1)          original test set    0.178 (+6.736%)  0.144   \n",
       "                          generated test set  0.478 (-69.983%)  1.645   \n",
       "m4_hourly (m=1)           original test set    0.172 (+2.922%)  0.144   \n",
       "                          generated test set  0.065 (-74.784%)  0.387   \n",
       "m4_daily (k=100)          original test set    0.031 (+2.151%)   0.03   \n",
       "                          generated test set  0.385 (-42.231%)  0.666   \n",
       "m4_weekly (f=0.01)        original test set    0.085 (+1.201%)  0.083   \n",
       "                          generated test set  0.112 (-51.666%)   0.19   \n",
       "m4_monthly (m=1)          original test set     0.14 (+1.834%)  0.134   \n",
       "                          generated test set  0.063 (-15.041%)   0.07   \n",
       "m4_monthly (h=0.01)       original test set   0.155 (+13.037%)  0.134   \n",
       "                          generated test set  0.841 (-26.304%)  1.088   \n",
       "m4_monthly (f=0.01)       original test set    0.136 (-0.759%)  0.134   \n",
       "                          generated test set  0.081 (-15.968%)  0.095   \n",
       "m4_quarterly (h=0.01)     original test set   0.118 (+11.967%)  0.105   \n",
       "                          generated test set  0.984 (-17.044%)  1.142   \n",
       "m4_quarterly (m=-1)       original test set     0.112 (+6.48%)  0.105   \n",
       "                          generated test set  0.616 (-48.721%)  1.154   \n",
       "m4_yearly (h=0.01)        original test set   0.154 (+11.069%)  0.142   \n",
       "                          generated test set   1.037 (-9.501%)  1.141   \n",
       "\n",
       "                                                               N-BEATS  \\\n",
       "                                                     augmented     old   \n",
       "electricity_nips (k=0.01) original test set    0.121 (+4.182%)   0.096   \n",
       "                          generated test set  0.097 (-11.105%)   0.086   \n",
       "electricity_nips (m=-1)   original test set    0.115 (-1.041%)   0.096   \n",
       "                          generated test set  1.079 (-22.473%)   0.823   \n",
       "electricity_nips (m=1)    original test set    0.122 (+4.889%)   0.096   \n",
       "                          generated test set  0.109 (-51.589%)   0.123   \n",
       "traffic_nips (m=1)        original test set    0.201 (+8.111%)   0.089   \n",
       "                          generated test set   0.204 (-19.94%)   0.123   \n",
       "traffic_nips (f=0.01)     original test set    0.173 (-6.947%)   0.089   \n",
       "                          generated test set  0.432 (-17.654%)   0.225   \n",
       "m4_hourly (m=-1)          original test set     0.14 (-2.725%)   0.111   \n",
       "                          generated test set   0.547 (-66.73%)   1.617   \n",
       "m4_hourly (m=1)           original test set   0.168 (+16.594%)   0.111   \n",
       "                          generated test set  0.083 (-78.519%)   0.275   \n",
       "m4_daily (k=100)          original test set     0.03 (-0.853%)    0.03   \n",
       "                          generated test set   0.37 (-44.423%)   0.669   \n",
       "m4_weekly (f=0.01)        original test set    0.082 (-0.596%)   0.089   \n",
       "                          generated test set  0.118 (-37.729%)   0.064   \n",
       "m4_monthly (m=1)          original test set    0.137 (+2.401%)   0.128   \n",
       "                          generated test set  0.061 (-12.525%)   0.085   \n",
       "m4_monthly (h=0.01)       original test set     0.14 (+4.957%)   0.128   \n",
       "                          generated test set  0.773 (-28.998%)   1.189   \n",
       "m4_monthly (f=0.01)       original test set    0.134 (+0.367%)   0.128   \n",
       "                          generated test set   0.08 (-15.113%)   0.089   \n",
       "m4_quarterly (h=0.01)     original test set    0.113 (+8.295%)   0.099   \n",
       "                          generated test set  0.948 (-16.954%)   1.292   \n",
       "m4_quarterly (m=-1)       original test set    0.112 (+7.411%)   0.099   \n",
       "                          generated test set  0.592 (-48.666%)   1.318   \n",
       "m4_yearly (h=0.01)        original test set   0.166 (+17.483%)   0.136   \n",
       "                          generated test set   1.077 (-5.575%)   1.181   \n",
       "\n",
       "                                                                  TCN  \\\n",
       "                                                     augmented    old   \n",
       "electricity_nips (k=0.01) original test set    0.099 (+3.003%)  0.115   \n",
       "                          generated test set  0.062 (-27.453%)  0.095   \n",
       "electricity_nips (m=-1)   original test set    0.097 (+1.202%)  0.115   \n",
       "                          generated test set  0.522 (-36.667%)  1.183   \n",
       "electricity_nips (m=1)    original test set    0.097 (+1.374%)  0.115   \n",
       "                          generated test set  0.056 (-55.038%)  0.203   \n",
       "traffic_nips (m=1)        original test set    0.095 (+6.914%)  0.171   \n",
       "                          generated test set  0.055 (-55.549%)  0.327   \n",
       "traffic_nips (f=0.01)     original test set    0.095 (+6.851%)  0.171   \n",
       "                          generated test set   0.219 (-2.309%)   0.35   \n",
       "m4_hourly (m=-1)          original test set   0.146 (+31.405%)  0.156   \n",
       "                          generated test set  0.449 (-72.229%)  1.639   \n",
       "m4_hourly (m=1)           original test set    0.121 (+9.093%)  0.156   \n",
       "                          generated test set  0.048 (-82.628%)  0.356   \n",
       "m4_daily (k=100)          original test set     0.03 (-0.694%)  0.032   \n",
       "                          generated test set  0.381 (-42.984%)  0.693   \n",
       "m4_weekly (f=0.01)        original test set    0.093 (+4.635%)  0.082   \n",
       "                          generated test set   0.05 (-21.927%)  0.247   \n",
       "m4_monthly (m=1)          original test set    0.131 (+2.114%)   0.14   \n",
       "                          generated test set   0.06 (-28.639%)  0.079   \n",
       "m4_monthly (h=0.01)       original test set     0.13 (+1.714%)   0.14   \n",
       "                          generated test set  0.792 (-33.374%)  1.163   \n",
       "m4_monthly (f=0.01)       original test set     0.128 (-0.29%)   0.14   \n",
       "                          generated test set  0.079 (-10.894%)    0.1   \n",
       "m4_quarterly (h=0.01)     original test set    0.101 (+1.924%)  0.104   \n",
       "                          generated test set  1.015 (-21.447%)  1.192   \n",
       "m4_quarterly (m=-1)       original test set   0.109 (+10.157%)  0.104   \n",
       "                          generated test set  0.578 (-56.152%)  1.308   \n",
       "m4_yearly (h=0.01)        original test set    0.146 (+7.004%)  0.139   \n",
       "                          generated test set  0.908 (-23.079%)  1.119   \n",
       "\n",
       "                                                               Transformer  \\\n",
       "                                                     augmented         old   \n",
       "electricity_nips (k=0.01) original test set    0.14 (+21.752%)       0.111   \n",
       "                          generated test set  0.084 (-10.907%)       0.095   \n",
       "electricity_nips (m=-1)   original test set    0.122 (+5.976%)       0.111   \n",
       "                          generated test set  0.695 (-41.278%)       1.276   \n",
       "electricity_nips (m=1)    original test set   0.127 (+10.712%)       0.111   \n",
       "                          generated test set   0.08 (-60.759%)       0.167   \n",
       "traffic_nips (m=1)        original test set   0.224 (+31.106%)       0.207   \n",
       "                          generated test set  0.147 (-55.149%)       0.409   \n",
       "traffic_nips (f=0.01)     original test set   0.398 (+132.73%)       0.207   \n",
       "                          generated test set   0.337 (-3.588%)       0.642   \n",
       "m4_hourly (m=-1)          original test set    0.286 (+82.92%)       0.174   \n",
       "                          generated test set  0.661 (-59.711%)       1.628   \n",
       "m4_hourly (m=1)           original test set   0.176 (+12.257%)       0.174   \n",
       "                          generated test set  0.131 (-63.312%)       0.345   \n",
       "m4_daily (k=100)          original test set     0.031 (-3.88%)        0.03   \n",
       "                          generated test set  0.389 (-43.815%)       0.671   \n",
       "m4_weekly (f=0.01)        original test set   0.093 (+13.034%)       0.081   \n",
       "                          generated test set  0.143 (-42.339%)        0.06   \n",
       "m4_monthly (m=1)          original test set    0.153 (+9.471%)       0.136   \n",
       "                          generated test set  0.066 (-15.843%)       0.082   \n",
       "m4_monthly (h=0.01)       original test set    0.221 (+58.13%)       0.136   \n",
       "                          generated test set  0.772 (-33.618%)       1.183   \n",
       "m4_monthly (f=0.01)       original test set     0.143 (+2.81%)       0.136   \n",
       "                          generated test set   0.085 (-14.66%)       0.099   \n",
       "m4_quarterly (h=0.01)     original test set   0.116 (+11.484%)        0.11   \n",
       "                          generated test set  0.868 (-27.146%)       1.255   \n",
       "m4_quarterly (m=-1)       original test set   0.117 (+12.858%)        0.11   \n",
       "                          generated test set  0.638 (-51.246%)       1.176   \n",
       "m4_yearly (h=0.01)        original test set   0.157 (+13.041%)       0.143   \n",
       "                          generated test set  0.964 (-13.807%)       1.326   \n",
       "\n",
       "                                                                 \n",
       "                                                      augmented  \n",
       "electricity_nips (k=0.01) original test set      0.117 (+5.53%)  \n",
       "                          generated test set   0.079 (-16.837%)  \n",
       "electricity_nips (m=-1)   original test set     0.114 (+2.886%)  \n",
       "                          generated test set   0.617 (-51.666%)  \n",
       "electricity_nips (m=1)    original test set       0.12 (+8.19%)  \n",
       "                          generated test set   0.081 (-51.553%)  \n",
       "traffic_nips (m=1)        original test set   0.563 (+172.249%)  \n",
       "                          generated test set   0.287 (-29.751%)  \n",
       "traffic_nips (f=0.01)     original test set   0.555 (+168.215%)  \n",
       "                          generated test set    0.55 (-14.414%)  \n",
       "m4_hourly (m=-1)          original test set    0.198 (+13.727%)  \n",
       "                          generated test set   0.603 (-62.939%)  \n",
       "m4_hourly (m=1)           original test set      0.176 (+1.21%)  \n",
       "                          generated test set   0.078 (-77.327%)  \n",
       "m4_daily (k=100)          original test set      0.03 (-1.035%)  \n",
       "                          generated test set    0.42 (-37.394%)  \n",
       "m4_weekly (f=0.01)        original test set    0.093 (+14.638%)  \n",
       "                          generated test set   0.053 (-11.754%)  \n",
       "m4_monthly (m=1)          original test set      0.143 (+4.71%)  \n",
       "                          generated test set   0.064 (-21.745%)  \n",
       "m4_monthly (h=0.01)       original test set    0.151 (+10.565%)  \n",
       "                          generated test set   0.983 (-16.875%)  \n",
       "m4_monthly (f=0.01)       original test set       0.136 (-0.0%)  \n",
       "                          generated test set   0.083 (-15.588%)  \n",
       "m4_quarterly (h=0.01)     original test set     0.121 (+9.703%)  \n",
       "                          generated test set   1.074 (-14.451%)  \n",
       "m4_quarterly (m=-1)       original test set    0.122 (+10.957%)  \n",
       "                          generated test set   0.636 (-45.949%)  \n",
       "m4_yearly (h=0.01)        original test set     0.145 (+1.626%)  \n",
       "                          generated test set   1.093 (-17.576%)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c289e4f-f3e1-4698-8c75-50bddfb43caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|ll|cc|cc|cc|cc|cc|}\n",
      "\\toprule\n",
      "                   &                    & \\multicolumn{2}{c}{Fully-connected} & \\multicolumn{2}{c}{LSTM} & \\multicolumn{2}{c}{N-BEATS} & \\multicolumn{2}{c}{TCN} & \\multicolumn{2}{c}{Transformer} \\\\\n",
      "                   &                    &             old &         augmented &    old &         augmented &     old &         augmented &    old &         augmented &         old &          augmented \\\\\n",
      "\\midrule\n",
      "\\multirow{2}{*}{electricity\\_nips (k=0.01)} & original test set &           0.121 &  0.138 (+14.624\\%) &  0.116 &   0.121 (+4.182\\%) &   0.096 &   0.099 (+3.003\\%) &  0.115 &   0.14 (+21.752\\%) &       0.111 &     0.117 (+5.53\\%) \\\\\n",
      "                   & generated test set &           0.087 &  0.069 (-20.622\\%) &  0.109 &  0.097 (-11.105\\%) &   0.086 &  0.062 (-27.453\\%) &  0.095 &  0.084 (-10.907\\%) &       0.095 &   0.079 (-16.837\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{electricity\\_nips (m=-1)} & original test set &           0.121 &    0.112 (-7.42\\%) &  0.116 &   0.115 (-1.041\\%) &   0.096 &   0.097 (+1.202\\%) &  0.115 &   0.122 (+5.976\\%) &       0.111 &    0.114 (+2.886\\%) \\\\\n",
      "                   & generated test set &           1.372 &  0.535 (-60.974\\%) &  1.392 &  1.079 (-22.473\\%) &   0.823 &  0.522 (-36.667\\%) &  1.183 &  0.695 (-41.278\\%) &       1.276 &   0.617 (-51.666\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{electricity\\_nips (m=1)} & original test set &           0.121 &   0.109 (-9.738\\%) &  0.116 &   0.122 (+4.889\\%) &   0.096 &   0.097 (+1.374\\%) &  0.115 &  0.127 (+10.712\\%) &       0.111 &      0.12 (+8.19\\%) \\\\\n",
      "                   & generated test set &           0.194 &  0.053 (-72.449\\%) &  0.226 &  0.109 (-51.589\\%) &   0.123 &  0.056 (-55.038\\%) &  0.203 &   0.08 (-60.759\\%) &       0.167 &   0.081 (-51.553\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{traffic\\_nips (m=1)} & original test set &           0.168 &    0.173 (+2.69\\%) &  0.186 &   0.201 (+8.111\\%) &   0.089 &   0.095 (+6.914\\%) &  0.171 &  0.224 (+31.106\\%) &       0.207 &  0.563 (+172.249\\%) \\\\\n",
      "                   & generated test set &           0.156 &  0.067 (-57.065\\%) &  0.255 &   0.204 (-19.94\\%) &   0.123 &  0.055 (-55.549\\%) &  0.327 &  0.147 (-55.149\\%) &       0.409 &   0.287 (-29.751\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{traffic\\_nips (f=0.01)} & original test set &           0.168 &    0.159 (-5.34\\%) &  0.186 &   0.173 (-6.947\\%) &   0.089 &   0.095 (+6.851\\%) &  0.171 &  0.398 (+132.73\\%) &       0.207 &  0.555 (+168.215\\%) \\\\\n",
      "                   & generated test set &           0.257 &   0.239 (-6.942\\%) &  0.524 &  0.432 (-17.654\\%) &   0.225 &   0.219 (-2.309\\%) &   0.35 &   0.337 (-3.588\\%) &       0.642 &    0.55 (-14.414\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_hourly (m=-1)} & original test set &           0.167 &   0.178 (+6.736\\%) &  0.144 &    0.14 (-2.725\\%) &   0.111 &  0.146 (+31.405\\%) &  0.156 &   0.286 (+82.92\\%) &       0.174 &   0.198 (+13.727\\%) \\\\\n",
      "                   & generated test set &           1.593 &  0.478 (-69.983\\%) &  1.645 &   0.547 (-66.73\\%) &   1.617 &  0.449 (-72.229\\%) &  1.639 &  0.661 (-59.711\\%) &       1.628 &   0.603 (-62.939\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_hourly (m=1)} & original test set &           0.167 &   0.172 (+2.922\\%) &  0.144 &  0.168 (+16.594\\%) &   0.111 &   0.121 (+9.093\\%) &  0.156 &  0.176 (+12.257\\%) &       0.174 &     0.176 (+1.21\\%) \\\\\n",
      "                   & generated test set &           0.259 &  0.065 (-74.784\\%) &  0.387 &  0.083 (-78.519\\%) &   0.275 &  0.048 (-82.628\\%) &  0.356 &  0.131 (-63.312\\%) &       0.345 &   0.078 (-77.327\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_daily (k=100)} & original test set &            0.03 &   0.031 (+2.151\\%) &   0.03 &    0.03 (-0.853\\%) &    0.03 &    0.03 (-0.694\\%) &  0.032 &    0.031 (-3.88\\%) &        0.03 &     0.03 (-1.035\\%) \\\\\n",
      "                   & generated test set &           0.667 &  0.385 (-42.231\\%) &  0.666 &   0.37 (-44.423\\%) &   0.669 &  0.381 (-42.984\\%) &  0.693 &  0.389 (-43.815\\%) &       0.671 &    0.42 (-37.394\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_weekly (f=0.01)} & original test set &           0.084 &   0.085 (+1.201\\%) &  0.083 &   0.082 (-0.596\\%) &   0.089 &   0.093 (+4.635\\%) &  0.082 &  0.093 (+13.034\\%) &       0.081 &   0.093 (+14.638\\%) \\\\\n",
      "                   & generated test set &           0.232 &  0.112 (-51.666\\%) &   0.19 &  0.118 (-37.729\\%) &   0.064 &   0.05 (-21.927\\%) &  0.247 &  0.143 (-42.339\\%) &        0.06 &   0.053 (-11.754\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (m=1)} & original test set &           0.137 &    0.14 (+1.834\\%) &  0.134 &   0.137 (+2.401\\%) &   0.128 &   0.131 (+2.114\\%) &   0.14 &   0.153 (+9.471\\%) &       0.136 &     0.143 (+4.71\\%) \\\\\n",
      "                   & generated test set &           0.074 &  0.063 (-15.041\\%) &   0.07 &  0.061 (-12.525\\%) &   0.085 &   0.06 (-28.639\\%) &  0.079 &  0.066 (-15.843\\%) &       0.082 &   0.064 (-21.745\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (h=0.01)} & original test set &           0.137 &  0.155 (+13.037\\%) &  0.134 &    0.14 (+4.957\\%) &   0.128 &    0.13 (+1.714\\%) &   0.14 &   0.221 (+58.13\\%) &       0.136 &   0.151 (+10.565\\%) \\\\\n",
      "                   & generated test set &           1.141 &  0.841 (-26.304\\%) &  1.088 &  0.773 (-28.998\\%) &   1.189 &  0.792 (-33.374\\%) &  1.163 &  0.772 (-33.618\\%) &       1.183 &   0.983 (-16.875\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_monthly (f=0.01)} & original test set &           0.137 &   0.136 (-0.759\\%) &  0.134 &   0.134 (+0.367\\%) &   0.128 &    0.128 (-0.29\\%) &   0.14 &    0.143 (+2.81\\%) &       0.136 &      0.136 (-0.0\\%) \\\\\n",
      "                   & generated test set &           0.096 &  0.081 (-15.968\\%) &  0.095 &   0.08 (-15.113\\%) &   0.089 &  0.079 (-10.894\\%) &    0.1 &   0.085 (-14.66\\%) &       0.099 &   0.083 (-15.588\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_quarterly (h=0.01)} & original test set &           0.105 &  0.118 (+11.967\\%) &  0.105 &   0.113 (+8.295\\%) &   0.099 &   0.101 (+1.924\\%) &  0.104 &  0.116 (+11.484\\%) &        0.11 &    0.121 (+9.703\\%) \\\\\n",
      "                   & generated test set &           1.187 &  0.984 (-17.044\\%) &  1.142 &  0.948 (-16.954\\%) &   1.292 &  1.015 (-21.447\\%) &  1.192 &  0.868 (-27.146\\%) &       1.255 &   1.074 (-14.451\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_quarterly (m=-1)} & original test set &           0.105 &    0.112 (+6.48\\%) &  0.105 &   0.112 (+7.411\\%) &   0.099 &  0.109 (+10.157\\%) &  0.104 &  0.117 (+12.858\\%) &        0.11 &   0.122 (+10.957\\%) \\\\\n",
      "                   & generated test set &           1.201 &  0.616 (-48.721\\%) &  1.154 &  0.592 (-48.666\\%) &   1.318 &  0.578 (-56.152\\%) &  1.308 &  0.638 (-51.246\\%) &       1.176 &   0.636 (-45.949\\%) \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow{2}{*}{m4\\_yearly (h=0.01)} & original test set &           0.138 &  0.154 (+11.069\\%) &  0.142 &  0.166 (+17.483\\%) &   0.136 &   0.146 (+7.004\\%) &  0.139 &  0.157 (+13.041\\%) &       0.143 &    0.145 (+1.626\\%) \\\\\n",
      "                   & generated test set &           1.146 &   1.037 (-9.501\\%) &  1.141 &   1.077 (-5.575\\%) &   1.181 &  0.908 (-23.079\\%) &  1.119 &  0.964 (-13.807\\%) &       1.326 &   1.093 (-17.576\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(multirow=True, column_format=\"|ll|cc|cc|cc|cc|cc|\", multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e25a99b-9671-49ff-9de7-216a70959117",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "std_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "median_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "\n",
    "old_degen_average_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "old_degen_std_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "old_degen_median_changes_per_transform = {dataset: {} for dataset in dataset_suffixes.keys()}\n",
    "\n",
    "per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood_degen\": []} for model_name in model_names}\n",
    "\n",
    "all_old = []\n",
    "all_generated = []\n",
    "all_ood_degen = []\n",
    "for dataset in scores_dict.keys():\n",
    "    for suffix in dataset_suffixes[dataset]:\n",
    "        old_percentages = []\n",
    "        generated_percentages = []\n",
    "        ood_degen_percentages = []\n",
    "        for model in scores_dict[dataset]:\n",
    "            old_original_score = scores_dict[dataset][model][suffix][\"original model\"][\"orig\"]\n",
    "            old_generated_score = scores_dict[dataset][model][suffix][\"original model\"][\"ood\"]\n",
    "            new_original_score = scores_dict[dataset][model][suffix][\"new model\"][\"orig\"]\n",
    "            new_generated_score = scores_dict[dataset][model][suffix][\"new model\"][\"ood\"]\n",
    "            \n",
    "            old_percentage = (np.abs(old_original_score - new_original_score) / old_original_score) * 100\n",
    "            generated_percentage = (np.abs(old_generated_score - new_generated_score) / old_generated_score) * 100\n",
    "            ood_degeneration_percentage = (np.abs(old_original_score - old_generated_score) / old_original_score) * 100\n",
    "            \n",
    "            old_percentage = old_percentage if new_original_score >= old_original_score else -old_percentage\n",
    "            generated_percentage = generated_percentage if new_generated_score >= old_generated_score else -generated_percentage\n",
    "            ood_degeneration_percentage = ood_degeneration_percentage if old_generated_score >= old_original_score else -ood_degeneration_percentage\n",
    "            \n",
    "            old_percentages.append(old_percentage)\n",
    "            generated_percentages.append(generated_percentage)\n",
    "            ood_degen_percentages.append(ood_degeneration_percentage)\n",
    "            \n",
    "            per_model_percentages[model][\"original\"].append(old_percentage)\n",
    "            per_model_percentages[model][\"generated\"].append(generated_percentage)\n",
    "            per_model_percentages[model][\"ood_degen\"].append(ood_degeneration_percentage)\n",
    "            \n",
    "            all_old.append(old_percentage)\n",
    "            all_generated.append(generated_percentage)\n",
    "            all_ood_degen.append(ood_degeneration_percentage)\n",
    "\n",
    "        average_changes_per_transform[dataset][suffix] = {\"original test set\": np.mean(old_percentages), \"generated test set\": np.mean(generated_percentages)}\n",
    "        std_changes_per_transform[dataset][suffix] = {\"original test set\": np.std(old_percentages), \"generated test set\": np.std(generated_percentages)}\n",
    "        median_changes_per_transform[dataset][suffix] = {\"original test set\": np.median(old_percentages), \"generated test set\": np.median(generated_percentages)}\n",
    "        \n",
    "        old_degen_average_changes_per_transform[dataset][suffix] = np.mean(ood_degen_percentages)\n",
    "        old_degen_std_changes_per_transform[dataset][suffix] = np.std(ood_degen_percentages)\n",
    "        old_degen_median_changes_per_transform[dataset][suffix] = np.median(ood_degen_percentages)\n",
    "\n",
    "\n",
    "average_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names}\n",
    "std_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names}\n",
    "median_per_model_percentages = {model_name: {\"original\": [], \"generated\": [], \"ood\": []} for model_name in model_names} \n",
    "for model in per_model_percentages:\n",
    "    average_per_model_percentages[model][\"original\"] = np.mean(per_model_percentages[model][\"original\"])\n",
    "    average_per_model_percentages[model][\"generated\"] = np.mean(per_model_percentages[model][\"generated\"])\n",
    "    average_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])\n",
    "    \n",
    "    std_per_model_percentages[model][\"original\"] = np.std(per_model_percentages[model][\"original\"])\n",
    "    std_per_model_percentages[model][\"generated\"] = np.std(per_model_percentages[model][\"generated\"])\n",
    "    std_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])\n",
    "    \n",
    "    median_per_model_percentages[model][\"original\"] = np.median(per_model_percentages[model][\"original\"])\n",
    "    median_per_model_percentages[model][\"generated\"] = np.median(per_model_percentages[model][\"generated\"])\n",
    "    median_per_model_percentages[model][\"ood\"] = np.mean(per_model_percentages[model][\"ood_degen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f1252-a801-4efc-8c1a-d2146ef6250b",
   "metadata": {},
   "source": [
    "# Differences between the augmented and the old models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ad1171-9ce0-4d65-8231-c6cfa2fbfddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_nips\n",
      "\t (k=0.01)\n",
      "\t\tAverage percentage change on original test set:  9.818\n",
      "\t\tAverage percentage change on generated test set: -17.385\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  7.24\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.222\n",
      "\n",
      "\t\tMedian percentage change on original test set:  5.53\n",
      "\t\tMedian percentage change on generated test set: -16.837\n",
      "electricity_nips\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  0.321\n",
      "\t\tAverage percentage change on generated test set: -42.612\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  4.497\n",
      "\t\tStandard deviation of percentage change on generated test set: 13.129\n",
      "\n",
      "\t\tMedian percentage change on original test set:  1.202\n",
      "\t\tMedian percentage change on generated test set: -41.278\n",
      "electricity_nips\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  3.085\n",
      "\t\tAverage percentage change on generated test set: -58.277\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  7.139\n",
      "\t\tStandard deviation of percentage change on generated test set: 7.841\n",
      "\n",
      "\t\tMedian percentage change on original test set:  4.889\n",
      "\t\tMedian percentage change on generated test set: -55.038\n",
      "traffic_nips\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  44.214\n",
      "\t\tAverage percentage change on generated test set: -43.491\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  64.782\n",
      "\t\tStandard deviation of percentage change on generated test set: 15.55\n",
      "\n",
      "\t\tMedian percentage change on original test set:  8.111\n",
      "\t\tMedian percentage change on generated test set: -55.149\n",
      "traffic_nips\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  59.102\n",
      "\t\tAverage percentage change on generated test set: -8.982\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  75.594\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.041\n",
      "\n",
      "\t\tMedian percentage change on original test set:  6.851\n",
      "\t\tMedian percentage change on generated test set: -6.942\n",
      "m4_hourly\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  26.412\n",
      "\t\tAverage percentage change on generated test set: -66.318\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  30.381\n",
      "\t\tStandard deviation of percentage change on generated test set: 4.552\n",
      "\n",
      "\t\tMedian percentage change on original test set:  13.727\n",
      "\t\tMedian percentage change on generated test set: -66.73\n",
      "m4_hourly\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  8.415\n",
      "\t\tAverage percentage change on generated test set: -75.314\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  5.73\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.514\n",
      "\n",
      "\t\tMedian percentage change on original test set:  9.093\n",
      "\t\tMedian percentage change on generated test set: -77.327\n",
      "m4_daily\n",
      "\t (k=100)\n",
      "\t\tAverage percentage change on original test set:  -0.862\n",
      "\t\tAverage percentage change on generated test set: -42.169\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  1.91\n",
      "\t\tStandard deviation of percentage change on generated test set: 2.5\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -0.853\n",
      "\t\tMedian percentage change on generated test set: -42.984\n",
      "m4_weekly\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  6.582\n",
      "\t\tAverage percentage change on generated test set: -33.083\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  6.177\n",
      "\t\tStandard deviation of percentage change on generated test set: 14.367\n",
      "\n",
      "\t\tMedian percentage change on original test set:  4.635\n",
      "\t\tMedian percentage change on generated test set: -37.729\n",
      "m4_monthly\n",
      "\t (m=1)\n",
      "\t\tAverage percentage change on original test set:  4.106\n",
      "\t\tAverage percentage change on generated test set: -18.759\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  2.87\n",
      "\t\tStandard deviation of percentage change on generated test set: 5.792\n",
      "\n",
      "\t\tMedian percentage change on original test set:  2.401\n",
      "\t\tMedian percentage change on generated test set: -15.843\n",
      "m4_monthly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  17.681\n",
      "\t\tAverage percentage change on generated test set: -27.834\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  20.616\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.131\n",
      "\n",
      "\t\tMedian percentage change on original test set:  10.565\n",
      "\t\tMedian percentage change on generated test set: -28.998\n",
      "m4_monthly\n",
      "\t (f=0.01)\n",
      "\t\tAverage percentage change on original test set:  0.426\n",
      "\t\tAverage percentage change on generated test set: -14.445\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  1.248\n",
      "\t\tStandard deviation of percentage change on generated test set: 1.829\n",
      "\n",
      "\t\tMedian percentage change on original test set:  -0.0\n",
      "\t\tMedian percentage change on generated test set: -15.113\n",
      "m4_quarterly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  8.675\n",
      "\t\tAverage percentage change on generated test set: -19.408\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  3.62\n",
      "\t\tStandard deviation of percentage change on generated test set: 4.477\n",
      "\n",
      "\t\tMedian percentage change on original test set:  9.703\n",
      "\t\tMedian percentage change on generated test set: -17.044\n",
      "m4_quarterly\n",
      "\t (m=-1)\n",
      "\t\tAverage percentage change on original test set:  9.573\n",
      "\t\tAverage percentage change on generated test set: -50.147\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  2.336\n",
      "\t\tStandard deviation of percentage change on generated test set: 3.439\n",
      "\n",
      "\t\tMedian percentage change on original test set:  10.157\n",
      "\t\tMedian percentage change on generated test set: -48.721\n",
      "m4_yearly\n",
      "\t (h=0.01)\n",
      "\t\tAverage percentage change on original test set:  10.044\n",
      "\t\tAverage percentage change on generated test set: -13.908\n",
      "\n",
      "\t\tStandard deviation of percentage change on original test set:  5.394\n",
      "\t\tStandard deviation of percentage change on generated test set: 6.106\n",
      "\n",
      "\t\tMedian percentage change on original test set:  11.069\n",
      "\t\tMedian percentage change on generated test set: -13.807\n"
     ]
    }
   ],
   "source": [
    "for dataset in average_changes_per_transform:\n",
    "    for suffix in average_changes_per_transform[dataset]:\n",
    "        print(dataset)\n",
    "        print(f\"\\t{suffix_to_transformation[suffix]}\")\n",
    "        print(f\"\\t\\tAverage percentage change on original test set:  {np.round(average_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tAverage percentage change on generated test set: {np.round(average_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")\n",
    "        print()\n",
    "        print(f\"\\t\\tStandard deviation of percentage change on original test set:  {np.round(std_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tStandard deviation of percentage change on generated test set: {np.round(std_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")\n",
    "        print()\n",
    "        print(f\"\\t\\tMedian percentage change on original test set:  {np.round(median_changes_per_transform[dataset][suffix]['original test set'], 3)}\")\n",
    "        print(f\"\\t\\tMedian percentage change on generated test set: {np.round(median_changes_per_transform[dataset][suffix]['generated test set'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8940f8cb-6079-44dd-ba1e-07f7f39f7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully-connected\n",
      "\tAverage percentage change on original test set:  3.43\n",
      "\tAverage percentage change on generated test set: -39.286\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  7.139\n",
      "\tStandard deviation of percentage change on generated test set: 23.687\n",
      "\n",
      "\tMedian percentage change on original test set:  2.69\n",
      "\tMedian percentage change on generated test set: -42.231\n",
      "LSTM\n",
      "\tAverage percentage change on original test set:  4.169\n",
      "\tAverage percentage change on generated test set: -31.866\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  6.53\n",
      "\tStandard deviation of percentage change on generated test set: 21.127\n",
      "\n",
      "\tMedian percentage change on original test set:  4.182\n",
      "\tMedian percentage change on generated test set: -22.473\n",
      "N-BEATS\n",
      "\tAverage percentage change on original test set:  5.76\n",
      "\tAverage percentage change on generated test set: -38.025\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  7.588\n",
      "\tStandard deviation of percentage change on generated test set: 21.759\n",
      "\n",
      "\tMedian percentage change on original test set:  3.003\n",
      "\tMedian percentage change on generated test set: -33.374\n",
      "TCN\n",
      "\tAverage percentage change on original test set:  27.627\n",
      "\tAverage percentage change on generated test set: -35.812\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  35.51\n",
      "\tStandard deviation of percentage change on generated test set: 19.608\n",
      "\n",
      "\tMedian percentage change on original test set:  12.858\n",
      "\tMedian percentage change on generated test set: -41.278\n",
      "Transformer\n",
      "\tAverage percentage change on original test set:  28.211\n",
      "\tAverage percentage change on generated test set: -32.388\n",
      "\n",
      "\tStandard deviation of percentage change on original test set:  55.91\n",
      "\tStandard deviation of percentage change on generated test set: 20.126\n",
      "\n",
      "\tMedian percentage change on original test set:  8.19\n",
      "\tMedian percentage change on generated test set: -21.745\n"
     ]
    }
   ],
   "source": [
    "for model in average_per_model_percentages:\n",
    "    print(model)\n",
    "    print(f\"\\tAverage percentage change on original test set:  {np.round(average_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tAverage percentage change on generated test set: {np.round(average_per_model_percentages[model]['generated'], 3)}\")\n",
    "    print()\n",
    "    print(f\"\\tStandard deviation of percentage change on original test set:  {np.round(std_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tStandard deviation of percentage change on generated test set: {np.round(std_per_model_percentages[model]['generated'], 3)}\")\n",
    "    print()\n",
    "    print(f\"\\tMedian percentage change on original test set:  {np.round(median_per_model_percentages[model]['original'], 3)}\")\n",
    "    print(f\"\\tMedian percentage change on generated test set: {np.round(median_per_model_percentages[model]['generated'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beea9137-f1ff-4f4b-9ad9-89847f7026e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage change on original test set:  13.839\n",
      "Average percentage change on generated test set: -35.475\n",
      "\n",
      "Standard deviation of percentage change on original test set:  32.255\n",
      "Standard deviation of percentage change on generated test set: 21.513\n",
      "\n",
      "Median percentage change on original test set:  5.976\n",
      "Median percentage change on generated test set: -29.751\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average percentage change on original test set:  {np.round(np.mean(all_old), 3)}\")\n",
    "print(f\"Average percentage change on generated test set: {np.round(np.mean(all_generated), 3)}\")\n",
    "print()\n",
    "print(f\"Standard deviation of percentage change on original test set:  {np.round(np.std(all_old), 3)}\")\n",
    "print(f\"Standard deviation of percentage change on generated test set: {np.round(np.std(all_generated), 3)}\")\n",
    "print()\n",
    "print(f\"Median percentage change on original test set:  {np.round(np.median(all_old), 3)}\")\n",
    "print(f\"Median percentage change on generated test set: {np.round(np.median(all_generated), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6d94a-24e7-416d-9f67-e4b64af6307b",
   "metadata": {},
   "source": [
    "# How much did the performance of the original models degenerate when faced with OOD data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b45e9cc-0d34-4154-a15f-6794923a20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity_nips\n",
      "\t (k=0.01)\n",
      "\t\tAverage OOD percentage change:  -15.425\n",
      "\t\tStandard deviation of OOD percentage change:  7.205\n",
      "\t\tMedian OOD percentage change:  -14.879\n",
      "electricity_nips\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  974.4\n",
      "\t\tStandard deviation of OOD percentage change:  122.014\n",
      "\t\tMedian OOD percentage change:  1036.313\n",
      "electricity_nips\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  62.216\n",
      "\t\tStandard deviation of OOD percentage change:  22.779\n",
      "\t\tMedian OOD percentage change:  60.757\n",
      "traffic_nips\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  51.612\n",
      "\t\tStandard deviation of OOD percentage change:  38.671\n",
      "\t\tMedian OOD percentage change:  39.193\n",
      "traffic_nips\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  140.633\n",
      "\t\tStandard deviation of OOD percentage change:  56.104\n",
      "\t\tMedian OOD percentage change:  153.605\n",
      "m4_hourly\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  1008.454\n",
      "\t\tStandard deviation of OOD percentage change:  190.645\n",
      "\t\tMedian OOD percentage change:  947.977\n",
      "m4_hourly\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  119.58\n",
      "\t\tStandard deviation of OOD percentage change:  39.773\n",
      "\t\tMedian OOD percentage change:  127.586\n",
      "m4_daily\n",
      "\t (k=100)\n",
      "\t\tAverage OOD percentage change:  2102.89\n",
      "\t\tStandard deviation of OOD percentage change:  19.52\n",
      "\t\tMedian OOD percentage change:  2100.485\n",
      "m4_weekly\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  90.387\n",
      "\t\tStandard deviation of OOD percentage change:  98.746\n",
      "\t\tMedian OOD percentage change:  128.926\n",
      "m4_monthly\n",
      "\t (m=1)\n",
      "\t\tAverage OOD percentage change:  -42.235\n",
      "\t\tStandard deviation of OOD percentage change:  4.943\n",
      "\t\tMedian OOD percentage change:  -43.599\n",
      "m4_monthly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  754.731\n",
      "\t\tStandard deviation of OOD percentage change:  40.68\n",
      "\t\tMedian OOD percentage change:  733.603\n",
      "m4_monthly\n",
      "\t (f=0.01)\n",
      "\t\tAverage OOD percentage change:  -29.242\n",
      "\t\tStandard deviation of OOD percentage change:  1.167\n",
      "\t\tMedian OOD percentage change:  -29.392\n",
      "m4_quarterly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  1063.178\n",
      "\t\tStandard deviation of OOD percentage change:  73.2\n",
      "\t\tMedian OOD percentage change:  1042.009\n",
      "m4_quarterly\n",
      "\t (m=-1)\n",
      "\t\tAverage OOD percentage change:  1081.483\n",
      "\t\tStandard deviation of OOD percentage change:  98.514\n",
      "\t\tMedian OOD percentage change:  1043.541\n",
      "m4_yearly\n",
      "\t (h=0.01)\n",
      "\t\tAverage OOD percentage change:  746.341\n",
      "\t\tStandard deviation of OOD percentage change:  46.378\n",
      "\t\tMedian OOD percentage change:  728.929\n"
     ]
    }
   ],
   "source": [
    "for dataset in average_changes_per_transform:\n",
    "    for suffix in average_changes_per_transform[dataset]:\n",
    "        print(dataset)\n",
    "        print(f\"\\t{suffix_to_transformation[suffix]}\")\n",
    "        print(f\"\\t\\tAverage OOD percentage change:  {np.round(old_degen_average_changes_per_transform[dataset][suffix], 3)}\")\n",
    "        print(f\"\\t\\tStandard deviation of OOD percentage change:  {np.round(old_degen_std_changes_per_transform[dataset][suffix], 3)}\")\n",
    "        print(f\"\\t\\tMedian OOD percentage change:  {np.round(old_degen_median_changes_per_transform[dataset][suffix], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c0fd0c7-12e9-49a4-82ff-9852fdbb8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully-connected\n",
      "\tAverage percentage change on OOD:  517.243\n",
      "\tStandard deviation of percentage change on OOD:  517.243\n",
      "\tMedian percentage change on OOD:  517.243\n",
      "LSTM\n",
      "\tAverage percentage change on OOD:  545.131\n",
      "\tStandard deviation of percentage change on OOD:  545.131\n",
      "\tMedian percentage change on OOD:  545.131\n",
      "N-BEATS\n",
      "\tAverage percentage change on OOD:  570.03\n",
      "\tStandard deviation of percentage change on OOD:  570.03\n",
      "\tMedian percentage change on OOD:  570.03\n",
      "TCN\n",
      "\tAverage percentage change on OOD:  541.245\n",
      "\tStandard deviation of percentage change on OOD:  541.245\n",
      "\tMedian percentage change on OOD:  541.245\n",
      "Transformer\n",
      "\tAverage percentage change on OOD:  529.351\n",
      "\tStandard deviation of percentage change on OOD:  529.351\n",
      "\tMedian percentage change on OOD:  529.351\n"
     ]
    }
   ],
   "source": [
    "for model in average_per_model_percentages:\n",
    "    print(model)\n",
    "    print(f\"\\tAverage percentage change on OOD:  {np.round(average_per_model_percentages[model]['ood'], 3)}\")\n",
    "    print(f\"\\tStandard deviation of percentage change on OOD:  {np.round(std_per_model_percentages[model]['ood'], 3)}\")\n",
    "    print(f\"\\tMedian percentage change on OOD:  {np.round(median_per_model_percentages[model]['ood'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be2ade73-4841-4250-9191-eb908be36494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage change on OOD: 540.6\n",
      "Standard deviation of percentage change on OOD: 609.38\n",
      "Median percentage change on OOD: 181.734\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average percentage change on OOD: {np.round(np.mean(all_ood_degen), 3)}\")\n",
    "print(f\"Standard deviation of percentage change on OOD: {np.round(np.std(all_ood_degen), 3)}\")\n",
    "print(f\"Median percentage change on OOD: {np.round(np.median(all_ood_degen), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b2a59-868c-4537-b306-4ef40d97c828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
